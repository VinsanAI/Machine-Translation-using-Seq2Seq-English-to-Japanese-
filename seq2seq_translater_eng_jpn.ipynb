{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq: Translation Chatbot with Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Translation – A Brief History\n",
    "Most of us were introduced to machine translation when Google came up with the service. But the concept has been around since the middle of last century.\n",
    "\n",
    "Research work in Machine Translation (MT) started as early as 1950’s, primarily in the United States. These early systems relied on huge bilingual dictionaries, hand-coded rules, and universal principles underlying natural language.\n",
    "\n",
    "In 1954, IBM held a first ever public demonstration of a machine translation. The system had a pretty small vocabulary of only 250 words and it could translate only 49 hand-picked Russian sentences to English. The number seems minuscule now but the system is widely regarded as an important milestone in the progress of machine translation.\n",
    "\n",
    "Soon, two schools of thought emerged:\n",
    "\n",
    "- Empirical trial-and-error approaches, using statistical methods, and\n",
    "- Theoretical approaches involving fundamental linguistic research\n",
    "\n",
    "In 1964, the Automatic Language Processing Advisory Committee (ALPAC) was established by the United States government to evaluate the progress in Machine Translation. ALPAC did a little prodding around and published a report in November 1966 on the state of MT. Below are the key highlights from that report:\n",
    "\n",
    "- It raised serious questions on the feasibility of machine translation and termed it hopeless\n",
    "- Funding was discouraged for MT research\n",
    "- It was quite a depressing report for the researchers working in this field\n",
    "- Most of them left the field and started new careers\n",
    "\n",
    "Not exactly a glowing recommendation!\n",
    "\n",
    "A long dry period followed this miserable report. Finally, in 1981, a new system called the METEO System was deployed in Canada for translation of weather forecasts issued in French into English. It was quite a successful project which stayed in operation until 2001.\n",
    "\n",
    "The world’s first web translation tool, Babel Fish, was launched by the AltaVista search engine in 1997.\n",
    "\n",
    "And then came the breakthrough we are all familiar with now – Google Translate. It has since changed the way we work (and even learn) with different languages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to Sequence-to-Sequence (Seq2Seq) Modeling\n",
    "Sequence-to-Sequence (seq2seq) models are used for a variety of NLP tasks, such as text summarization, speech recognition, DNA sequence modeling, among others. Our aim is to translate given sentences from one language to another.\n",
    "\n",
    "Here, both the input and output are sentences. In other words, these sentences are a sequence of words going in and out of a model. This is the basic idea of Sequence-to-Sequence modeling. \n",
    "\n",
    "A typical seq2seq model has 2 major components –\n",
    "\n",
    "- an encoder\n",
    "- a decoder\n",
    "\n",
    "Both these parts are essentially two different recurrent neural network (RNN) models combined into one giant network\n",
    "\n",
    "Use cases of Sequence-to-Sequence modeling below (apart from Machine Translation, of course):\n",
    "\n",
    "- Speech Recognition\n",
    "- Name Entity/Subject Extraction to identify the main subject from a body of text\n",
    "- Relation Classification to tag relationships between various entities tagged in the above step\n",
    "- Chatbot skills to have conversational ability and engage with customers\n",
    "- Text Summarization to generate a concise summary of a large amount of text\n",
    "- Question Answering systems\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business example\n",
    "\n",
    "For our example implementation, we will use a dataset of pairs of English sentences and their German translation.\n",
    "\n",
    "We will implement a character-level sequence-to-sequence model, processing the input character-by-character and generating the output character-by-character. Another option would be a word-level model, which tends to be more common for machine translation. \n",
    "\n",
    "#### Here's a summary of our process:\n",
    "\n",
    "- 1) Turn the sentences into 3 Numpy arrays, encoder_input_data, decoder_input_data, decoder_target_data:\n",
    "    - encoder_input_data is a 3D array of shape (num_pairs, max_english_sentence_length, num_english_characters) containing a one-hot vectorization of the English sentences.\n",
    "    - decoder_input_data is a 3D array of shape (num_pairs, max_french_sentence_length, num_german_characters) containg a one-hot vectorization of the French sentences.\n",
    "    - decoder_target_data is the same as decoder_input_data but offset by one timestep. decoder_target_data[:, t, :] will be the same as decoder_input_data[:, t + 1, :].\n",
    "- 2) Train a basic LSTM-based Seq2Seq model to predict decoder_target_data given encoder_input_data and decoder_input_data. Our model uses teacher forcing.\n",
    "- 3) Decode some sentences to check that the model is working (i.e. turn samples from encoder_input_data into corresponding samples from decoder_target_data).\n",
    "Because the training process and inference process (decoding sentences) are quite different, we use different models for both, albeit they all leverage the same inner layers.\n",
    "\n",
    "This is our training model. It leverages three key features of Keras RNNs:\n",
    "\n",
    "- The return_state contructor argument, configuring a RNN layer to return a list where the first entry is the outputs and the next entries are the internal RNN states. This is used to recover the states of the encoder.\n",
    "- The inital_state call argument, specifying the initial state(s) of a RNN. This is used to pass the encoder states to the decoder as initial states.\n",
    "- The return_sequences constructor argument, configuring a RNN to return its full sequence of outputs (instead of just the last output, which the defaults behavior). This is used in the decoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary of the algorithm**\n",
    "- We start with input sequences from a domain (e.g. English sentences)\n",
    "    and corresponding target sequences from another domain\n",
    "    (e.g. German sentences).\n",
    "- An encoder LSTM turns input sequences to 2 state vectors\n",
    "    (we keep the last LSTM state and discard the outputs).\n",
    "- A decoder LSTM is trained to turn the target sequences into\n",
    "    the same sequence but offset by one timestep in the future,\n",
    "    a training process called \"teacher forcing\" in this context.\n",
    "    It uses as initial state the state vectors from the encoder.\n",
    "    Effectively, the decoder learns to generate `targets[t+1...]`\n",
    "    given `targets[...t]`, conditioned on the input sequence.\n",
    "- In inference mode, when we want to decode unknown input sequences, we:\n",
    "    - Encode the input sequence into state vectors\n",
    "    - Start with a target sequence of size 1\n",
    "        (just the start-of-sequence character)\n",
    "    - Feed the state vectors and 1-char target sequence\n",
    "        to the decoder to produce predictions for the next character\n",
    "    - Sample the next character using these predictions\n",
    "        (we simply use argmax).\n",
    "    - Append the sampled character to the target sequence\n",
    "    - Repeat until we generate the end-of-sequence character or we\n",
    "        hit the character limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://cdn-images-1.medium.com/max/2600/1*1I2tTjCkMHlQ-r73eRn4ZQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder-Decoder\n",
    "1. Sentence Data（encoder_input_data、decoder_input_data、decoder_target_data).\n",
    "  - encoder_input_data（num_pairs、max_english_sentence_length、num_english_characters）\n",
    "  - decoder_input_data（num_pairs、max_french_sentence_length、num_french_characters）\n",
    "  - decoder_target_data (decoder_input_data 1 Time Step).\n",
    "2. encoder_input_data, decoder_input_data, decoder_target_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is 809A-5B06\n",
      "\n",
      " Directory of C:\\Users\\USER\\Desktop\\Text Mining\\seq2seq_translate_slackbot-master\n",
      "\n",
      "10/05/2019  09:02 AM    <DIR>          .\n",
      "10/05/2019  09:02 AM    <DIR>          ..\n",
      "03/18/2019  10:31 AM             6,148 .DS_Store\n",
      "09/26/2019  08:06 PM    <DIR>          .ipynb_checkpoints\n",
      "10/05/2019  09:02 AM            93,146 0315_seq2seq_translater.ipynb\n",
      "03/18/2019  10:31 AM               725 attention.py\n",
      "03/18/2019  10:31 AM             1,689 explain_mention.py\n",
      "07/30/2018  04:21 PM        10,200,869 fra.txt\n",
      "03/18/2019  10:31 AM         3,574,873 jpn.txt\n",
      "04/14/2019  08:14 AM           104,442 Neural machine translation - Encoder-Decoder seq2seq model-New.ipynb\n",
      "03/18/2019  10:31 AM    <DIR>          plugins\n",
      "03/18/2019  10:31 AM             2,228 README.md\n",
      "03/18/2019  10:31 AM               156 run.py\n",
      "03/18/2019  10:31 AM               726 seq2seq_attention.py\n",
      "03/18/2019  10:31 AM            12,388 seq2seq_translate.py\n",
      "03/18/2019  10:31 AM        19,962,264 seq2seq_translate_model.txt\n",
      "09/26/2019  08:26 PM            50,256 seq2seq_translater.ipynb\n",
      "03/18/2019  10:31 AM               383 slackbot_setting.py\n",
      "              14 File(s)     34,010,293 bytes\n",
      "               4 Dir(s)   3,673,243,648 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import pickle\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocess feeding data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Importing input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"jpn.txt\", 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43954"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Go.\\t行け。'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = lines[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating input & target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_texts = []\n",
    "target_texts = []\n",
    "bos = \"<BOS> \"\n",
    "eos = \" <EOS>\"\n",
    "\n",
    "for line in lines:\n",
    "    if len(line.split(\"\\t\")) == 2:\n",
    "        input_text, target_text = line.split(\"\\t\")[0], line.split(\"\\t\")[1]\n",
    "        target_text = bos + target_text + eos\n",
    "        input_texts.append(input_text)\n",
    "        target_texts.append(target_text)\n",
    "\n",
    "len(input_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Go.',\n",
       " 'Go.',\n",
       " 'Hi.',\n",
       " 'Hi.',\n",
       " 'Run.',\n",
       " 'Run.',\n",
       " 'Who?',\n",
       " 'Wow!',\n",
       " 'Wow!',\n",
       " 'Wow!',\n",
       " 'Fire!',\n",
       " 'Fire!',\n",
       " 'Help!',\n",
       " 'Jump!',\n",
       " 'Jump!',\n",
       " 'Jump!',\n",
       " 'Jump!',\n",
       " 'Jump!',\n",
       " 'Jump.',\n",
       " 'Jump.',\n",
       " 'Jump.',\n",
       " 'Stop!',\n",
       " 'Stop!',\n",
       " 'Wait!',\n",
       " 'Go on.',\n",
       " 'Go on.',\n",
       " 'Go on.',\n",
       " 'Go on.',\n",
       " 'Hello!',\n",
       " 'Hello!',\n",
       " 'Hello!',\n",
       " 'Hurry!',\n",
       " 'I see.',\n",
       " 'I see.',\n",
       " 'I see.',\n",
       " 'I see.',\n",
       " 'I see.',\n",
       " 'I see.',\n",
       " 'I see.',\n",
       " 'I try.',\n",
       " 'I try.',\n",
       " 'I try.',\n",
       " 'I try.',\n",
       " 'I try.',\n",
       " 'I won!',\n",
       " 'I won!',\n",
       " 'I won!',\n",
       " 'I won!',\n",
       " 'I won!',\n",
       " 'Oh no!',\n",
       " 'Oh no!',\n",
       " 'Oh no!',\n",
       " 'Oh no!',\n",
       " 'Oh no!',\n",
       " 'Oh no!',\n",
       " 'Relax.',\n",
       " 'Relax.',\n",
       " 'Relax.',\n",
       " 'Shoot!',\n",
       " 'Smile.',\n",
       " 'Smile.',\n",
       " 'Cheers!',\n",
       " 'Freeze!',\n",
       " 'Get up.',\n",
       " 'Get up.',\n",
       " 'Get up.',\n",
       " 'Go now.',\n",
       " 'Got it!',\n",
       " 'Got it!',\n",
       " 'He ran.',\n",
       " 'He ran.',\n",
       " 'Hop in.',\n",
       " 'Hop in.',\n",
       " 'Hug me.',\n",
       " 'Hug me.',\n",
       " 'I know.',\n",
       " 'I know.',\n",
       " 'I left.',\n",
       " 'I lost.',\n",
       " 'I quit.',\n",
       " 'I quit.',\n",
       " \"I'm 19.\",\n",
       " \"I'm OK.\",\n",
       " \"I'm OK.\",\n",
       " \"I'm up.\",\n",
       " 'Listen.',\n",
       " 'Listen.',\n",
       " 'No way!',\n",
       " 'No way!',\n",
       " 'No way!',\n",
       " 'No way!',\n",
       " 'Really?',\n",
       " 'Really?',\n",
       " 'Thanks.',\n",
       " 'Thanks.',\n",
       " 'We try.',\n",
       " 'We won.',\n",
       " 'We won.',\n",
       " 'Why me?',\n",
       " 'Why me?',\n",
       " 'Ask Tom.',\n",
       " 'Ask Tom.',\n",
       " 'Ask Tom.',\n",
       " 'Awesome!',\n",
       " 'Be calm.',\n",
       " 'Be cool.',\n",
       " 'Be cool.',\n",
       " 'Be fair.',\n",
       " 'Be kind.',\n",
       " 'Be nice.',\n",
       " 'Be nice.',\n",
       " 'Beat it.',\n",
       " 'Call me.',\n",
       " 'Call me.',\n",
       " 'Call us.',\n",
       " 'Come in.',\n",
       " 'Come in.',\n",
       " 'Come in.',\n",
       " 'Come in.',\n",
       " 'Come in.',\n",
       " 'Come on.',\n",
       " 'Come on.',\n",
       " 'Get Tom.',\n",
       " 'Get out!',\n",
       " 'Get out!',\n",
       " 'Get out!',\n",
       " 'Get out.',\n",
       " 'Get out.',\n",
       " 'Get out.',\n",
       " 'Get out.',\n",
       " 'Get out.',\n",
       " 'Go away!',\n",
       " 'Go away!',\n",
       " 'Go away!',\n",
       " 'Go away.',\n",
       " 'Go away.',\n",
       " 'Go away.',\n",
       " 'Go away.',\n",
       " 'Go home.',\n",
       " 'Go slow.',\n",
       " 'Go slow.',\n",
       " 'Goodbye!',\n",
       " 'Goodbye!',\n",
       " 'Hang on!',\n",
       " 'Hang on.',\n",
       " 'He came.',\n",
       " 'He quit.',\n",
       " 'He runs.',\n",
       " 'Help me!',\n",
       " 'Help me!',\n",
       " 'Help me.',\n",
       " 'Help me.',\n",
       " 'Help me.',\n",
       " 'Help me.',\n",
       " 'Help me.',\n",
       " 'Help us.',\n",
       " 'Hi, Tom.',\n",
       " 'Hi, Tom.',\n",
       " 'Hit Tom.',\n",
       " 'Hold it!',\n",
       " 'Hold it!',\n",
       " 'Hold it!',\n",
       " 'Hold on.',\n",
       " 'Hug Tom.',\n",
       " 'Hug Tom.',\n",
       " 'Hug Tom.',\n",
       " 'I agree.',\n",
       " 'I agree.',\n",
       " 'I agree.',\n",
       " 'I agree.',\n",
       " 'I tried.',\n",
       " 'I tried.',\n",
       " \"I'll go.\",\n",
       " \"I'll go.\",\n",
       " \"I'm Tom.\",\n",
       " \"I'm Tom.\",\n",
       " \"I'm Tom.\",\n",
       " \"I'm fat.\",\n",
       " \"I'm fat.\",\n",
       " \"I'm old.\",\n",
       " \"I'm sad.\",\n",
       " \"I'm shy.\",\n",
       " \"It's OK.\",\n",
       " \"It's me!\",\n",
       " \"It's me!\",\n",
       " \"It's me.\",\n",
       " \"It's me.\",\n",
       " 'Join us.',\n",
       " 'Keep it.',\n",
       " 'Me, too.',\n",
       " 'Me, too.',\n",
       " 'Me, too.',\n",
       " 'Open up.',\n",
       " 'Open up.',\n",
       " 'Perfect!',\n",
       " 'See you!',\n",
       " 'See you.',\n",
       " 'See you.',\n",
       " 'See you.',\n",
       " 'Show me.',\n",
       " 'Show me.',\n",
       " 'Shut up!',\n",
       " 'Skip it.',\n",
       " 'So long.',\n",
       " 'Stop it.',\n",
       " 'Stop it.',\n",
       " 'Stop it.',\n",
       " 'Stop it.',\n",
       " 'Take it.',\n",
       " 'Tell me.',\n",
       " 'Tom ate.',\n",
       " 'Tom ran.',\n",
       " 'Tom won.',\n",
       " 'Tom won.',\n",
       " 'Wait up.',\n",
       " 'Wake up!',\n",
       " 'Wake up!',\n",
       " 'Wake up!',\n",
       " 'Wake up.',\n",
       " 'Wake up.',\n",
       " 'Wake up.',\n",
       " 'Wake up.',\n",
       " 'Wash up.',\n",
       " 'Wash up.',\n",
       " 'We know.',\n",
       " 'We know.',\n",
       " 'We know.',\n",
       " 'We lost.',\n",
       " 'Welcome.',\n",
       " 'Welcome.',\n",
       " 'Welcome.',\n",
       " 'Who ran?',\n",
       " 'Who won?',\n",
       " 'Why not?',\n",
       " 'Why not?',\n",
       " 'You run.',\n",
       " 'You won.',\n",
       " 'You won.',\n",
       " 'Am I fat?',\n",
       " 'Back off!',\n",
       " 'Back off!',\n",
       " 'Be a man.',\n",
       " 'Be quiet.',\n",
       " 'Be quiet.',\n",
       " 'Be quiet.',\n",
       " 'Be quiet.',\n",
       " 'Be quiet.',\n",
       " 'Be quiet.',\n",
       " 'Be still.',\n",
       " 'Call Tom.',\n",
       " 'Call Tom.',\n",
       " 'Cheer up!',\n",
       " 'Cheer up!',\n",
       " 'Cheer up!',\n",
       " 'Cheer up!',\n",
       " 'Cheer up.',\n",
       " 'Cheer up.',\n",
       " 'Cool off!',\n",
       " \"Don't go.\",\n",
       " \"Don't go.\",\n",
       " 'Find Tom.',\n",
       " 'Find Tom.',\n",
       " 'Get away!',\n",
       " 'Get down!',\n",
       " 'Get lost!',\n",
       " 'Get lost.',\n",
       " 'Get lost.',\n",
       " 'Get real!',\n",
       " 'Go ahead!',\n",
       " 'Go ahead.',\n",
       " 'Go ahead.',\n",
       " 'Good job!',\n",
       " 'Good job!',\n",
       " 'Good job!',\n",
       " 'Grab Tom.',\n",
       " 'Have fun.',\n",
       " 'Have fun.',\n",
       " 'He tries.',\n",
       " 'Help Tom.',\n",
       " 'How cute!',\n",
       " 'How cute!',\n",
       " 'How deep?',\n",
       " 'Hurry up.',\n",
       " 'Hurry up.',\n",
       " 'I did it.',\n",
       " 'I did it.',\n",
       " 'I forgot.',\n",
       " 'I forgot.',\n",
       " 'I got it.',\n",
       " 'I resign.',\n",
       " 'I use it.',\n",
       " 'I yawned.',\n",
       " \"I'll pay.\",\n",
       " \"I'll pay.\",\n",
       " \"I'll pay.\",\n",
       " \"I'll pay.\",\n",
       " \"I'll pay.\",\n",
       " \"I'll try.\",\n",
       " \"I'll try.\",\n",
       " \"I'll try.\",\n",
       " \"I'm busy.\",\n",
       " \"I'm busy.\",\n",
       " \"I'm busy.\",\n",
       " \"I'm cool.\",\n",
       " \"I'm cool.\",\n",
       " \"I'm fair.\",\n",
       " \"I'm fine.\",\n",
       " \"I'm fine.\",\n",
       " \"I'm free.\",\n",
       " \"I'm free.\",\n",
       " \"I'm free.\",\n",
       " \"I'm free.\",\n",
       " \"I'm free.\",\n",
       " \"I'm full.\",\n",
       " \"I'm full.\",\n",
       " \"I'm lost.\",\n",
       " \"I'm poor.\",\n",
       " \"I'm sick.\",\n",
       " \"I'm tall.\",\n",
       " \"I'm well.\",\n",
       " \"I'm well.\",\n",
       " \"I'm well.\",\n",
       " \"It's Tom.\",\n",
       " \"It's new.\",\n",
       " 'Keep out.',\n",
       " 'Leave it.',\n",
       " 'Leave it.',\n",
       " 'Leave it.',\n",
       " \"Let's go!\",\n",
       " \"Let's go!\",\n",
       " 'Look out!',\n",
       " 'Marry me.',\n",
       " 'Speak up!',\n",
       " 'Stand up!',\n",
       " 'Stand up!',\n",
       " 'Stand up.',\n",
       " 'Stand up.',\n",
       " 'Tell Tom.',\n",
       " 'Tell Tom.',\n",
       " 'Terrific!',\n",
       " 'Terrific!',\n",
       " 'They won.',\n",
       " 'Tom came.',\n",
       " 'Tom died.',\n",
       " 'Tom fell.',\n",
       " 'Tom knew.',\n",
       " 'Tom left.',\n",
       " 'Tom lied.',\n",
       " 'Tom lies.',\n",
       " 'Tom lost.',\n",
       " 'Tom paid.',\n",
       " 'Tom quit.',\n",
       " 'Tom swam.',\n",
       " 'Tom wept.',\n",
       " 'Tom wept.',\n",
       " 'Tom wept.',\n",
       " 'Too late.',\n",
       " 'Trust me.',\n",
       " 'Trust me.',\n",
       " 'Try hard.',\n",
       " 'Use this.',\n",
       " 'Warn Tom.',\n",
       " 'Warn Tom.',\n",
       " 'Warn Tom.',\n",
       " 'Warn Tom.',\n",
       " 'We agree.',\n",
       " 'What for?',\n",
       " 'What for?',\n",
       " 'Who came?',\n",
       " 'Who came?',\n",
       " 'Who died?',\n",
       " 'Who quit?',\n",
       " 'After you.',\n",
       " 'Birds fly.',\n",
       " 'Call home!',\n",
       " 'Calm down!',\n",
       " 'Calm down!',\n",
       " 'Calm down!',\n",
       " 'Calm down!',\n",
       " 'Calm down!',\n",
       " 'Calm down.',\n",
       " 'Calm down.',\n",
       " 'Calm down.',\n",
       " 'Calm down.',\n",
       " 'Calm down.',\n",
       " 'Calm down.',\n",
       " 'Calm down.',\n",
       " 'Calm down.',\n",
       " 'Calm down.',\n",
       " 'Catch him.',\n",
       " 'Catch him.',\n",
       " 'Chill out.',\n",
       " 'Come back.',\n",
       " 'Come here.',\n",
       " 'Come here.',\n",
       " 'Come here.',\n",
       " 'Come here.',\n",
       " 'Come here.',\n",
       " 'Come here.',\n",
       " 'Come here.',\n",
       " 'Come here.',\n",
       " 'Come home.',\n",
       " 'Come home.',\n",
       " 'Come home.',\n",
       " 'Come home.',\n",
       " 'Come home.',\n",
       " 'Come over!',\n",
       " 'Come over!',\n",
       " 'Come over!',\n",
       " 'Come over!',\n",
       " 'Come soon.',\n",
       " 'Cool down.',\n",
       " 'Cool down.',\n",
       " 'Did I win?',\n",
       " 'Dogs bark.',\n",
       " \"Don't ask.\",\n",
       " \"Don't cry.\",\n",
       " \"Don't die.\",\n",
       " \"Don't lie.\",\n",
       " 'Excuse me.',\n",
       " 'Excuse me.',\n",
       " 'Excuse me.',\n",
       " 'Excuse me?',\n",
       " 'Fantastic!',\n",
       " 'Fantastic!',\n",
       " 'Fantastic!',\n",
       " 'Follow me.',\n",
       " 'Follow me.',\n",
       " 'Forget it.',\n",
       " 'Get going.',\n",
       " 'Go to bed.',\n",
       " 'Good luck.',\n",
       " 'Good luck.',\n",
       " 'Hands off.',\n",
       " 'He is old.',\n",
       " \"He's a DJ.\",\n",
       " \"He's lazy.\",\n",
       " 'How awful!',\n",
       " 'How is it?',\n",
       " 'Humor Tom.',\n",
       " 'I am busy.',\n",
       " 'I am calm.',\n",
       " 'I am full.',\n",
       " 'I am sure.',\n",
       " 'I am sure.',\n",
       " 'I am tall.',\n",
       " 'I can run.',\n",
       " 'I can ski.',\n",
       " 'I fainted.',\n",
       " 'I give in.',\n",
       " 'I give up.',\n",
       " 'I give up.',\n",
       " 'I got mad.',\n",
       " 'I had fun.',\n",
       " 'I have it.',\n",
       " 'I hit Tom.',\n",
       " 'I hope so.',\n",
       " 'I hope so.',\n",
       " 'I laughed.',\n",
       " 'I mean it!',\n",
       " 'I mean it.',\n",
       " 'I met him.',\n",
       " 'I must go.',\n",
       " 'I promise.',\n",
       " 'I relaxed.',\n",
       " 'I said no.',\n",
       " 'I said no.',\n",
       " 'I said so.',\n",
       " 'I saw him.',\n",
       " 'I saw him.',\n",
       " 'I see Tom.',\n",
       " 'I want it.',\n",
       " 'I was mad.',\n",
       " 'I will go.',\n",
       " 'I will go.',\n",
       " \"I'd agree.\",\n",
       " \"I'll help.\",\n",
       " \"I'll help.\",\n",
       " \"I'll help.\",\n",
       " \"I'm a boy.\",\n",
       " \"I'm a cop.\",\n",
       " \"I'm alone.\",\n",
       " \"I'm alone.\",\n",
       " \"I'm awake.\",\n",
       " \"I'm bored.\",\n",
       " \"I'm brave.\",\n",
       " \"I'm broke.\",\n",
       " \"I'm broke.\",\n",
       " \"I'm clean.\",\n",
       " \"I'm clean.\",\n",
       " \"I'm dizzy.\",\n",
       " \"I'm dizzy.\",\n",
       " \"I'm drunk.\",\n",
       " \"I'm dying.\",\n",
       " \"I'm early.\",\n",
       " \"I'm first.\",\n",
       " \"I'm fussy.\",\n",
       " \"I'm fussy.\",\n",
       " \"I'm happy.\",\n",
       " \"I'm happy.\",\n",
       " \"I'm happy.\",\n",
       " \"I'm lucky.\",\n",
       " \"I'm ready.\",\n",
       " \"I'm smart.\",\n",
       " \"I'm smart.\",\n",
       " \"I'm sober.\",\n",
       " \"I'm sorry.\",\n",
       " \"I'm sorry.\",\n",
       " \"I'm sorry.\",\n",
       " \"I'm sorry.\",\n",
       " \"I'm tired.\",\n",
       " \"I'm tired.\",\n",
       " \"I'm tired.\",\n",
       " \"I'm tired.\",\n",
       " \"I'm tired.\",\n",
       " \"I'm young.\",\n",
       " 'Is he Tom?',\n",
       " 'Is it far?',\n",
       " 'It stinks.',\n",
       " 'It worked.',\n",
       " 'It worked.',\n",
       " \"It's 3:30.\",\n",
       " \"It's 7:45.\",\n",
       " \"It's 9:15.\",\n",
       " \"It's cold.\",\n",
       " \"It's cold.\",\n",
       " \"It's cool.\",\n",
       " \"It's easy.\",\n",
       " \"It's free.\",\n",
       " \"It's free.\",\n",
       " \"It's late.\",\n",
       " \"It's mine.\",\n",
       " \"It's mine.\",\n",
       " \"It's okay.\",\n",
       " \"It's work.\",\n",
       " 'Jump down.',\n",
       " 'Keep away.',\n",
       " 'Keep back.',\n",
       " 'Keep warm.',\n",
       " 'Let me go!',\n",
       " 'Let me in.',\n",
       " 'Let me in.',\n",
       " 'Let me in.',\n",
       " 'Let me in.',\n",
       " 'Let me in.',\n",
       " \"Let's try.\",\n",
       " 'Listen up.',\n",
       " 'Look back!',\n",
       " 'May I eat?',\n",
       " 'Of course!',\n",
       " 'Of course!',\n",
       " 'Of course!',\n",
       " 'Of course.',\n",
       " 'Of course.',\n",
       " 'Of course.',\n",
       " 'Of course.',\n",
       " 'Open fire!',\n",
       " 'Pardon me?',\n",
       " 'Pipe down!',\n",
       " 'Pipe down!',\n",
       " 'Pipe down.',\n",
       " 'Pipe down.',\n",
       " 'Read this.',\n",
       " 'Read this.',\n",
       " 'Say \"aah.\"',\n",
       " 'See above.',\n",
       " 'Seriously?',\n",
       " 'She cried.',\n",
       " 'She tried.',\n",
       " 'She tried.',\n",
       " 'Sign here.',\n",
       " 'Sit there.',\n",
       " 'Stay away.',\n",
       " 'Stay away.',\n",
       " 'Stay calm.',\n",
       " 'Stay calm.',\n",
       " 'Stay calm.',\n",
       " 'Step back.',\n",
       " 'Stop that!',\n",
       " 'Stop that!',\n",
       " 'Stop that.',\n",
       " 'Stop that.',\n",
       " 'Take care!',\n",
       " 'Take care!',\n",
       " 'Take care!',\n",
       " 'Take care!',\n",
       " 'Take care.',\n",
       " 'Take care.',\n",
       " 'Take care.',\n",
       " 'Take care.',\n",
       " 'Take care.',\n",
       " 'Take mine.',\n",
       " 'Take this.',\n",
       " 'Take this.',\n",
       " 'Thank you.',\n",
       " 'Thank you.',\n",
       " 'Thank you.',\n",
       " \"That's OK.\",\n",
       " \"That's it.\",\n",
       " \"That's it.\",\n",
       " 'They left.',\n",
       " 'They lied.',\n",
       " 'They lost.',\n",
       " 'They swam.',\n",
       " \"Time's up.\",\n",
       " 'Tom cooks.',\n",
       " 'Tom cried.',\n",
       " 'Tom cried.',\n",
       " 'Tom drank.',\n",
       " 'Tom drove.',\n",
       " 'Tom knits.',\n",
       " 'Tom knows.',\n",
       " 'Tom moved.',\n",
       " 'Tom moved.',\n",
       " 'Tom slept.',\n",
       " 'Tom slept.',\n",
       " 'Tom spoke.',\n",
       " 'Tom stood.',\n",
       " 'Tom tried.',\n",
       " 'Tom tried.',\n",
       " 'Tom tries.',\n",
       " 'Tom waved.',\n",
       " 'Tom waved.',\n",
       " 'Try again.',\n",
       " 'Try again.',\n",
       " 'Try again.',\n",
       " 'Turn left.',\n",
       " 'Wait here.',\n",
       " 'Watch out!',\n",
       " 'Watch out!',\n",
       " 'We did it!',\n",
       " 'We did it.',\n",
       " 'We forgot.',\n",
       " 'We talked.',\n",
       " 'We waited.',\n",
       " \"We're men.\",\n",
       " \"We've won!\",\n",
       " 'Well done!',\n",
       " 'Well done!',\n",
       " 'Well done!',\n",
       " 'Well done.',\n",
       " 'Well done.',\n",
       " \"What's up?\",\n",
       " \"What's up?\",\n",
       " 'Who cares?',\n",
       " 'Who is it?',\n",
       " 'Who is it?',\n",
       " 'Who is it?',\n",
       " 'Who knows?',\n",
       " \"Who'll go?\",\n",
       " \"Who's Tom?\",\n",
       " \"Who's she?\",\n",
       " 'Wonderful!',\n",
       " 'Wonderful!',\n",
       " 'Write Tom.',\n",
       " 'All aboard!',\n",
       " 'Am I clear?',\n",
       " 'Am I clear?',\n",
       " 'Am I fired?',\n",
       " 'Am I right?',\n",
       " 'Am I wrong?',\n",
       " 'Are you OK?',\n",
       " 'Are you OK?',\n",
       " 'Are you in?',\n",
       " 'Be careful!',\n",
       " 'Be careful.',\n",
       " 'Be careful.',\n",
       " 'Be careful.',\n",
       " 'Be on time.',\n",
       " 'Be patient.',\n",
       " 'Be serious.',\n",
       " 'Be serious.',\n",
       " 'Birds sing.',\n",
       " 'Birds sing.',\n",
       " 'Birds sing.',\n",
       " 'Bottoms up!',\n",
       " 'Can I come?',\n",
       " 'Can I help?',\n",
       " 'Can I help?',\n",
       " 'Carry this.',\n",
       " 'Choose one.',\n",
       " 'Come again.',\n",
       " 'Come along.',\n",
       " 'Come along.',\n",
       " 'Come along.',\n",
       " 'Come on in!',\n",
       " 'Come on in!',\n",
       " 'Come on in.',\n",
       " 'Come quick!',\n",
       " 'Come quick!',\n",
       " 'Come quick!',\n",
       " 'Come quick!',\n",
       " 'Cut it out!',\n",
       " 'Cut it out!',\n",
       " 'Cut it out.',\n",
       " 'Cut it out.',\n",
       " 'Deal me in.',\n",
       " 'Definitely!',\n",
       " 'Definitely!',\n",
       " 'Did Tom go?',\n",
       " 'Did we win?',\n",
       " 'Do come in!',\n",
       " 'Do come in.',\n",
       " 'Do you ski?',\n",
       " \"Don't come.\",\n",
       " \"Don't look.\",\n",
       " \"Don't move!\",\n",
       " \"Don't move!\",\n",
       " \"Don't move!\",\n",
       " \"Don't move.\",\n",
       " \"Don't move.\",\n",
       " \"Don't push.\",\n",
       " \"Don't talk!\",\n",
       " \"Don't talk!\",\n",
       " \"Don't talk.\",\n",
       " \"Don't wait.\",\n",
       " 'Eat slowly.',\n",
       " 'Fill it up.',\n",
       " 'Find a job.',\n",
       " 'Fire burns.',\n",
       " 'Follow Tom.',\n",
       " 'Forget him.',\n",
       " 'Forgive me.',\n",
       " 'Forgive us.',\n",
       " 'Get moving.',\n",
       " 'Get to bed.',\n",
       " 'Give it up.',\n",
       " 'Go on home.',\n",
       " 'Go see Tom.',\n",
       " 'Go to work.',\n",
       " 'Go wash up.',\n",
       " 'God exists.',\n",
       " 'Good night.',\n",
       " 'He ate out.',\n",
       " 'He gave in.',\n",
       " 'He gave up.',\n",
       " 'He hung up.',\n",
       " 'He is a DJ.',\n",
       " 'He is kind.',\n",
       " 'He is kind.',\n",
       " 'He is kind.',\n",
       " 'He is lazy.',\n",
       " 'He is nice.',\n",
       " 'He is nice.',\n",
       " 'He is sick.',\n",
       " 'He made it.',\n",
       " \"He's lying.\",\n",
       " \"He's lying.\",\n",
       " \"He's smart.\",\n",
       " \"He's smart.\",\n",
       " 'Heat it up.',\n",
       " 'Help me up.',\n",
       " 'Help me up.',\n",
       " 'Help me up.',\n",
       " 'Here he is!',\n",
       " 'Here it is.',\n",
       " 'Here it is.',\n",
       " 'Here we go.',\n",
       " 'Hey, relax.',\n",
       " 'Hold still.',\n",
       " 'How clever!',\n",
       " 'How lovely!',\n",
       " 'How tragic!',\n",
       " \"How's work?\",\n",
       " \"How's work?\",\n",
       " 'Hurry back.',\n",
       " 'Hurry home.',\n",
       " 'I admit it.',\n",
       " 'I am a boy.',\n",
       " 'I am a man.',\n",
       " 'I am happy.',\n",
       " 'I am happy.',\n",
       " 'I am happy.',\n",
       " 'I am tired.',\n",
       " 'I am tired.',\n",
       " 'I broke it.',\n",
       " 'I built it.',\n",
       " 'I can sing.',\n",
       " 'I can sing.',\n",
       " 'I can stay.',\n",
       " 'I can swim.',\n",
       " 'I can swim.',\n",
       " 'I can wait.',\n",
       " 'I can walk.',\n",
       " \"I can't go.\",\n",
       " \"I can't go.\",\n",
       " 'I disagree.',\n",
       " 'I disagree.',\n",
       " 'I disagree.',\n",
       " 'I doubt it.',\n",
       " 'I eat here.',\n",
       " 'I eat here.',\n",
       " 'I envy Tom.',\n",
       " 'I envy her.',\n",
       " 'I envy her.',\n",
       " 'I envy him.',\n",
       " 'I envy you.',\n",
       " 'I envy you.',\n",
       " 'I feel bad.',\n",
       " 'I feel old.',\n",
       " 'I found it.',\n",
       " 'I found it.',\n",
       " 'I got busy.',\n",
       " 'I got lost.',\n",
       " 'I got sick.',\n",
       " 'I hate Tom.',\n",
       " 'I have one.',\n",
       " 'I know Tom.',\n",
       " 'I know her.',\n",
       " 'I like Tom.',\n",
       " 'I like Tom.',\n",
       " 'I like him.',\n",
       " 'I like tea.',\n",
       " 'I like you.',\n",
       " 'I liked it.',\n",
       " 'I liked it.',\n",
       " 'I love her.',\n",
       " 'I love her.',\n",
       " 'I love her.',\n",
       " 'I love you.',\n",
       " 'I love you.',\n",
       " 'I love you.',\n",
       " 'I love you.',\n",
       " 'I miss Tom.',\n",
       " 'I miss you.',\n",
       " 'I miss you.',\n",
       " 'I must run.',\n",
       " 'I need Tom.',\n",
       " 'I need Tom.',\n",
       " 'I need you.',\n",
       " 'I need you.',\n",
       " 'I panicked.',\n",
       " 'I promised.',\n",
       " 'I think so.',\n",
       " 'I think so.',\n",
       " 'I think so.',\n",
       " 'I want you.',\n",
       " 'I was lost.',\n",
       " 'I was rude.',\n",
       " 'I was shot.',\n",
       " 'I was weak.',\n",
       " 'I will try.',\n",
       " 'I will try.',\n",
       " 'I work out.',\n",
       " 'I work out.',\n",
       " \"I'd accept.\",\n",
       " \"I'll be OK.\",\n",
       " \"I'll do it.\",\n",
       " \"I'll do it.\",\n",
       " \"I'll do it.\",\n",
       " \"I'll go in.\",\n",
       " \"I'm 30 now.\",\n",
       " \"I'm a twin.\",\n",
       " \"I'm amused.\",\n",
       " \"I'm biased.\",\n",
       " \"I'm biased.\",\n",
       " \"I'm coming.\",\n",
       " \"I'm coming.\",\n",
       " \"I'm coming.\",\n",
       " \"I'm direct.\",\n",
       " \"I'm eating.\",\n",
       " \"I'm for it.\",\n",
       " \"I'm honest.\",\n",
       " \"I'm hungry!\",\n",
       " \"I'm hungry!\",\n",
       " \"I'm hungry!\",\n",
       " \"I'm hungry!\",\n",
       " \"I'm hungry!\",\n",
       " \"I'm hungry.\",\n",
       " \"I'm hungry.\",\n",
       " \"I'm hungry.\",\n",
       " \"I'm joking.\",\n",
       " \"I'm lonely.\",\n",
       " \"I'm pooped.\",\n",
       " \"I'm scared.\",\n",
       " \"I'm single.\",\n",
       " \"I'm sleepy!\",\n",
       " \"I'm sleepy.\",\n",
       " \"I'm sleepy.\",\n",
       " \"I'm so fat.\",\n",
       " \"I'm twelve.\",\n",
       " \"I've eaten.\",\n",
       " 'Ignore Tom.',\n",
       " 'Is Tom mad?',\n",
       " 'Is he busy?',\n",
       " 'Is he tall?',\n",
       " 'Is it free?',\n",
       " 'Is it free?',\n",
       " 'Is it true?',\n",
       " 'Is that so?',\n",
       " 'Is that so?',\n",
       " 'It happens.',\n",
       " 'It is cold.',\n",
       " \"It's empty.\",\n",
       " \"It's funny.\",\n",
       " \"It's my CD.\",\n",
       " \"It's my CD.\",\n",
       " \"It's on me.\",\n",
       " \"It's on me.\",\n",
       " \"It's weird.\",\n",
       " \"It's weird.\",\n",
       " \"It's windy.\",\n",
       " 'Just do it.',\n",
       " 'Just relax.',\n",
       " 'Keep going.',\n",
       " 'Keep it up!',\n",
       " 'Keep it up.',\n",
       " 'Keep quiet!',\n",
       " 'Keep quiet.',\n",
       " 'Keep still.',\n",
       " 'Lean on me.',\n",
       " 'Lean on me.',\n",
       " 'Let Tom in.',\n",
       " 'Let him in.',\n",
       " 'Let him in.',\n",
       " 'Let him in.',\n",
       " 'Let me die.',\n",
       " 'Let me out!',\n",
       " 'Let me out.',\n",
       " 'Let me pay.',\n",
       " 'Let me pay.',\n",
       " 'Let me see.',\n",
       " 'Let me see.',\n",
       " 'Let me try.',\n",
       " \"Let's pray.\",\n",
       " \"Let's sing.\",\n",
       " \"Let's swim.\",\n",
       " 'Lighten up.',\n",
       " 'Look at it.',\n",
       " 'Look at me.',\n",
       " 'Look at me.',\n",
       " 'Never mind!',\n",
       " 'Never mind!',\n",
       " 'Never mind!',\n",
       " 'No problem!',\n",
       " 'No problem!',\n",
       " 'No problem.',\n",
       " 'No problem.',\n",
       " 'No problem.',\n",
       " 'No problem.',\n",
       " 'Once again.',\n",
       " 'Please sit.',\n",
       " 'Quiet down.',\n",
       " 'Say cheese.',\n",
       " 'Say please.',\n",
       " 'Say please.',\n",
       " 'She smiled.',\n",
       " 'She smiled.',\n",
       " 'Sing along.',\n",
       " 'Stand back!',\n",
       " 'Stay awake.',\n",
       " 'Stay quiet.',\n",
       " 'Stay still.',\n",
       " 'Stay there.',\n",
       " 'Step aside.',\n",
       " 'Study hard.',\n",
       " 'Take a bus.',\n",
       " 'Talk to me!',\n",
       " 'Talk to me!',\n",
       " 'That hurts.',\n",
       " 'That hurts.',\n",
       " \"That's new.\",\n",
       " 'They tried.',\n",
       " 'This is it.',\n",
       " 'This is it.',\n",
       " 'This is it.',\n",
       " 'This is it.',\n",
       " 'This is it.',\n",
       " 'This is it.',\n",
       " 'This works.',\n",
       " \"This'll do.\",\n",
       " 'Time flies.',\n",
       " 'Time is up.',\n",
       " 'Time is up.',\n",
       " 'Tom agreed.',\n",
       " 'Tom agrees.',\n",
       " 'Tom ate it.',\n",
       " 'Tom danced.',\n",
       " 'Tom drinks.',\n",
       " 'Tom drives.',\n",
       " 'Tom failed.',\n",
       " 'Tom forgot.',\n",
       " 'Tom fought.',\n",
       " 'Tom fought.',\n",
       " 'Tom helped.',\n",
       " 'Tom is mad.',\n",
       " 'Tom is new.',\n",
       " 'Tom is out.',\n",
       " 'Tom is wet.',\n",
       " 'Tom jumped.',\n",
       " 'Tom looked.',\n",
       " 'Tom nodded.',\n",
       " 'Tom phoned.',\n",
       " 'Tom sighed.',\n",
       " 'Tom smiled.',\n",
       " 'Tom smokes.',\n",
       " 'Tom talked.',\n",
       " 'Tom waited.',\n",
       " 'Tom winked.',\n",
       " 'Tom yawned.',\n",
       " ...]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<BOS> 行け。 <EOS>',\n",
       " '<BOS> 行きなさい。 <EOS>',\n",
       " '<BOS> やっほー。 <EOS>',\n",
       " '<BOS> こんにちは！ <EOS>',\n",
       " '<BOS> 走れ。 <EOS>',\n",
       " '<BOS> 走って！ <EOS>',\n",
       " '<BOS> 誰？ <EOS>',\n",
       " '<BOS> すごい！ <EOS>',\n",
       " '<BOS> ワォ！ <EOS>',\n",
       " '<BOS> わぉ！ <EOS>',\n",
       " '<BOS> 火事だ！ <EOS>',\n",
       " '<BOS> 火事！ <EOS>',\n",
       " '<BOS> 助けて！ <EOS>',\n",
       " '<BOS> 飛び越えろ！ <EOS>',\n",
       " '<BOS> 跳べ！ <EOS>',\n",
       " '<BOS> 飛び降りろ！ <EOS>',\n",
       " '<BOS> 飛び跳ねて！ <EOS>',\n",
       " '<BOS> ジャンプして！ <EOS>',\n",
       " '<BOS> 跳べ！ <EOS>',\n",
       " '<BOS> 飛び跳ねて！ <EOS>',\n",
       " '<BOS> ジャンプして！ <EOS>',\n",
       " '<BOS> やめろ！ <EOS>',\n",
       " '<BOS> 止まれ！ <EOS>',\n",
       " '<BOS> 待って！ <EOS>',\n",
       " '<BOS> 続けて。 <EOS>',\n",
       " '<BOS> 進んで。 <EOS>',\n",
       " '<BOS> 進め。 <EOS>',\n",
       " '<BOS> 続けろ。 <EOS>',\n",
       " '<BOS> こんにちは。 <EOS>',\n",
       " '<BOS> もしもし。 <EOS>',\n",
       " '<BOS> こんにちは！ <EOS>',\n",
       " '<BOS> 急げ！ <EOS>',\n",
       " '<BOS> なるほど。 <EOS>',\n",
       " '<BOS> なるほどね。 <EOS>',\n",
       " '<BOS> わかった。 <EOS>',\n",
       " '<BOS> わかりました。 <EOS>',\n",
       " '<BOS> そうですか。 <EOS>',\n",
       " '<BOS> そうなんだ。 <EOS>',\n",
       " '<BOS> そっか。 <EOS>',\n",
       " '<BOS> 頑張ってみる。 <EOS>',\n",
       " '<BOS> やってみる。 <EOS>',\n",
       " '<BOS> 試してみる。 <EOS>',\n",
       " '<BOS> やってみよう！ <EOS>',\n",
       " '<BOS> トライしてみる。 <EOS>',\n",
       " '<BOS> 俺の勝ちー！ <EOS>',\n",
       " '<BOS> 勝ったぁ！ <EOS>',\n",
       " '<BOS> 勝ったぞ！ <EOS>',\n",
       " '<BOS> 私の勝ち！ <EOS>',\n",
       " '<BOS> 私が勝ち！ <EOS>',\n",
       " '<BOS> なんてこった！ <EOS>',\n",
       " '<BOS> なんてことだ！ <EOS>',\n",
       " '<BOS> しまった！ <EOS>',\n",
       " '<BOS> あー、しまった！ <EOS>',\n",
       " '<BOS> うわ、しまった！ <EOS>',\n",
       " '<BOS> 何てことだ！ <EOS>',\n",
       " '<BOS> くつろいで。 <EOS>',\n",
       " '<BOS> リラックスして。 <EOS>',\n",
       " '<BOS> 楽にしてください。 <EOS>',\n",
       " '<BOS> 撃て！ <EOS>',\n",
       " '<BOS> はい、チーズ。 <EOS>',\n",
       " '<BOS> にっこり笑って。 <EOS>',\n",
       " '<BOS> 乾杯！ <EOS>',\n",
       " '<BOS> 動くな！ <EOS>',\n",
       " '<BOS> 起きなさい！ <EOS>',\n",
       " '<BOS> 起きなさい。 <EOS>',\n",
       " '<BOS> 起きろ！ <EOS>',\n",
       " '<BOS> さあ、行っといで。 <EOS>',\n",
       " '<BOS> 捕まえた。 <EOS>',\n",
       " '<BOS> 分かった！ <EOS>',\n",
       " '<BOS> 彼は走った。 <EOS>',\n",
       " '<BOS> 彼が走った。 <EOS>',\n",
       " '<BOS> 乗れよ。 <EOS>',\n",
       " '<BOS> さあ乗って。 <EOS>',\n",
       " '<BOS> 抱きしめて。 <EOS>',\n",
       " '<BOS> ぎゅーして。 <EOS>',\n",
       " '<BOS> 分かってる。 <EOS>',\n",
       " '<BOS> 分かってます。 <EOS>',\n",
       " '<BOS> 出発した <EOS>',\n",
       " '<BOS> 負けた・・・。 <EOS>',\n",
       " '<BOS> 私、辞めます。 <EOS>',\n",
       " '<BOS> やめた。 <EOS>',\n",
       " '<BOS> １９歳です。 <EOS>',\n",
       " '<BOS> 大丈夫ですよ。 <EOS>',\n",
       " '<BOS> 私は大丈夫です。 <EOS>',\n",
       " '<BOS> 起きてるよ。 <EOS>',\n",
       " '<BOS> 聞きなさい。 <EOS>',\n",
       " '<BOS> 聞いて！ <EOS>',\n",
       " '<BOS> 馬鹿な！ <EOS>',\n",
       " '<BOS> とんでもない！ <EOS>',\n",
       " '<BOS> とんでもございません！ <EOS>',\n",
       " '<BOS> とんでもありません！ <EOS>',\n",
       " '<BOS> 本当？ <EOS>',\n",
       " '<BOS> 本当に？ <EOS>',\n",
       " '<BOS> ありがとうございます！ <EOS>',\n",
       " '<BOS> ありがとう。 <EOS>',\n",
       " '<BOS> 私たちは努力しております。 <EOS>',\n",
       " '<BOS> 俺らの勝ちー！ <EOS>',\n",
       " '<BOS> 勝ったぞ！ <EOS>',\n",
       " '<BOS> 何でわたしなの？ <EOS>',\n",
       " '<BOS> どうして私なの？ <EOS>',\n",
       " '<BOS> トムに聞きなさい。 <EOS>',\n",
       " '<BOS> トムに聞いて。 <EOS>',\n",
       " '<BOS> トムに聞いてごらん。 <EOS>',\n",
       " '<BOS> すごいぞ！ <EOS>',\n",
       " '<BOS> 落ち着いて。 <EOS>',\n",
       " '<BOS> 落ち着いて。 <EOS>',\n",
       " '<BOS> 冷静に。 <EOS>',\n",
       " '<BOS> フェアに行こうぜ。 <EOS>',\n",
       " '<BOS> 譲り合いましょう。 <EOS>',\n",
       " '<BOS> お行儀よくしなさい。 <EOS>',\n",
       " '<BOS> 優しくしてあげなさい。 <EOS>',\n",
       " '<BOS> どっか行け。 <EOS>',\n",
       " '<BOS> 連絡をちょうだい。 <EOS>',\n",
       " '<BOS> 電話してね。 <EOS>',\n",
       " '<BOS> お電話ください。 <EOS>',\n",
       " '<BOS> 入っておいでよ。 <EOS>',\n",
       " '<BOS> お入りください。 <EOS>',\n",
       " '<BOS> 入ってきなさい！ <EOS>',\n",
       " '<BOS> 入って。 <EOS>',\n",
       " '<BOS> 入れ！ <EOS>',\n",
       " '<BOS> おいで。 <EOS>',\n",
       " '<BOS> おいおい。 <EOS>',\n",
       " '<BOS> トムを連れてきて。 <EOS>',\n",
       " '<BOS> 出て行け！ <EOS>',\n",
       " '<BOS> 出ていけ。 <EOS>',\n",
       " '<BOS> 出ろ！ <EOS>',\n",
       " '<BOS> 出て行け！ <EOS>',\n",
       " '<BOS> 出ていけ。 <EOS>',\n",
       " '<BOS> 外に出ろ。 <EOS>',\n",
       " '<BOS> 消え失せろ。 <EOS>',\n",
       " '<BOS> 出ろ！ <EOS>',\n",
       " '<BOS> 向こうへ行け！ <EOS>',\n",
       " '<BOS> あっちへ行け！ <EOS>',\n",
       " '<BOS> 離れろ。 <EOS>',\n",
       " '<BOS> 向こうへ行け！ <EOS>',\n",
       " '<BOS> どっか行け。 <EOS>',\n",
       " '<BOS> あっちへ行け！ <EOS>',\n",
       " '<BOS> 消え失せろ。 <EOS>',\n",
       " '<BOS> 帰りなさい。 <EOS>',\n",
       " '<BOS> ゆっくり、ゆっくり。 <EOS>',\n",
       " '<BOS> 慌てない、慌てない。 <EOS>',\n",
       " '<BOS> さようなら！ <EOS>',\n",
       " '<BOS> さようなら。 <EOS>',\n",
       " '<BOS> 頑張れ！ <EOS>',\n",
       " '<BOS> 切らないで。 <EOS>',\n",
       " '<BOS> 彼は来ました。 <EOS>',\n",
       " '<BOS> やめた。 <EOS>',\n",
       " '<BOS> 彼は走る。 <EOS>',\n",
       " '<BOS> 助けてくれ。 <EOS>',\n",
       " '<BOS> 助けて！ <EOS>',\n",
       " '<BOS> 助けてくれ。 <EOS>',\n",
       " '<BOS> 助けて！ <EOS>',\n",
       " '<BOS> 手伝ってよ。 <EOS>',\n",
       " '<BOS> 助けてください。 <EOS>',\n",
       " '<BOS> 手伝って。 <EOS>',\n",
       " '<BOS> 手伝って。 <EOS>',\n",
       " '<BOS> ハーイ、トム。 <EOS>',\n",
       " '<BOS> やぁ、トム。 <EOS>',\n",
       " '<BOS> トムを殴れ。 <EOS>',\n",
       " '<BOS> 動かないで！ <EOS>',\n",
       " '<BOS> 待って！ <EOS>',\n",
       " '<BOS> じっとして！ <EOS>',\n",
       " '<BOS> お待ちください。 <EOS>',\n",
       " '<BOS> トムを抱きしめて。 <EOS>',\n",
       " '<BOS> トムにハグして。 <EOS>',\n",
       " '<BOS> トムをハグして。 <EOS>',\n",
       " '<BOS> 賛成です。 <EOS>',\n",
       " '<BOS> 同感です。 <EOS>',\n",
       " '<BOS> そう思います。 <EOS>',\n",
       " '<BOS> まったくです。 <EOS>',\n",
       " '<BOS> やってはみた。 <EOS>',\n",
       " '<BOS> やってみた。 <EOS>',\n",
       " '<BOS> 行くよ。 <EOS>',\n",
       " '<BOS> 私が行きます。 <EOS>',\n",
       " '<BOS> トムと申します。 <EOS>',\n",
       " '<BOS> トムといいます。 <EOS>',\n",
       " '<BOS> 私はトムです。 <EOS>',\n",
       " '<BOS> 私は太っている。 <EOS>',\n",
       " '<BOS> 俺はデブだ。 <EOS>',\n",
       " '<BOS> 私ももう年だ。 <EOS>',\n",
       " '<BOS> 悲しいです。 <EOS>',\n",
       " '<BOS> 私は引っ込み思案です。 <EOS>',\n",
       " '<BOS> 大丈夫ですよ。 <EOS>',\n",
       " '<BOS> 僕だよ！ <EOS>',\n",
       " '<BOS> 私よ！ <EOS>',\n",
       " '<BOS> 私ですが。 <EOS>',\n",
       " '<BOS> 僕だよ！ <EOS>',\n",
       " '<BOS> 仲間になって。 <EOS>',\n",
       " '<BOS> 取っておいて。 <EOS>',\n",
       " '<BOS> 僕もだよ。 <EOS>',\n",
       " '<BOS> 私もそうです。 <EOS>',\n",
       " '<BOS> 私も。 <EOS>',\n",
       " '<BOS> 開けてくれ。 <EOS>',\n",
       " '<BOS> 開けろ。 <EOS>',\n",
       " '<BOS> バッチリ！ <EOS>',\n",
       " '<BOS> また会おう！ <EOS>',\n",
       " '<BOS> じゃ、またねっ！ <EOS>',\n",
       " '<BOS> じゃあ、またね。 <EOS>',\n",
       " '<BOS> また会おう！ <EOS>',\n",
       " '<BOS> 見せて。 <EOS>',\n",
       " '<BOS> ちょっと見せて。 <EOS>',\n",
       " '<BOS> 黙ってて。 <EOS>',\n",
       " '<BOS> やめておけ。 <EOS>',\n",
       " '<BOS> さようなら。 <EOS>',\n",
       " '<BOS> やめなさい。 <EOS>',\n",
       " '<BOS> やめろ！ <EOS>',\n",
       " '<BOS> いいかげんにして。 <EOS>',\n",
       " '<BOS> やめろよ。 <EOS>',\n",
       " '<BOS> これ取っておいて。 <EOS>',\n",
       " '<BOS> 教えて。 <EOS>',\n",
       " '<BOS> トムは食べた。 <EOS>',\n",
       " '<BOS> トムは走った。 <EOS>',\n",
       " '<BOS> トムは勝った。 <EOS>',\n",
       " '<BOS> トムの勝ち。 <EOS>',\n",
       " '<BOS> 待って！ <EOS>',\n",
       " '<BOS> 目を覚ませよ！ <EOS>',\n",
       " '<BOS> 起きなさい！ <EOS>',\n",
       " '<BOS> 起きて！ <EOS>',\n",
       " '<BOS> 目を覚ませよ！ <EOS>',\n",
       " '<BOS> 起きなさい！ <EOS>',\n",
       " '<BOS> 起きて！ <EOS>',\n",
       " '<BOS> 起きなさい。 <EOS>',\n",
       " '<BOS> 手を洗いなさい。 <EOS>',\n",
       " '<BOS> 顔を洗いなさい。 <EOS>',\n",
       " '<BOS> 私たちは知ってる。 <EOS>',\n",
       " '<BOS> 僕たちは知ってる。 <EOS>',\n",
       " '<BOS> 俺たちは知ってる。 <EOS>',\n",
       " '<BOS> 負けた・・・。 <EOS>',\n",
       " '<BOS> こんにちは。 <EOS>',\n",
       " '<BOS> いらっしゃい。 <EOS>',\n",
       " '<BOS> ようこそ。 <EOS>',\n",
       " '<BOS> 誰が走ったの？ <EOS>',\n",
       " '<BOS> 誰が勝ったの？ <EOS>',\n",
       " '<BOS> どうしてダメなの？ <EOS>',\n",
       " '<BOS> ぜひそうしよう。 <EOS>',\n",
       " '<BOS> 君が走れ。 <EOS>',\n",
       " '<BOS> あんたの勝ちだ。 <EOS>',\n",
       " '<BOS> おまえの勝ちだ。 <EOS>',\n",
       " '<BOS> 俺、太ってるかな？ <EOS>',\n",
       " '<BOS> 下がっていろ！ <EOS>',\n",
       " '<BOS> 引っ込んでて！ <EOS>',\n",
       " '<BOS> 男になれよ。 <EOS>',\n",
       " '<BOS> 黙っていなさい。 <EOS>',\n",
       " '<BOS> 静かに！ <EOS>',\n",
       " '<BOS> 少し静かにしていなさい。 <EOS>',\n",
       " '<BOS> 静かにしなさい。 <EOS>',\n",
       " '<BOS> 静かにしてなさい。 <EOS>',\n",
       " '<BOS> お静かに。 <EOS>',\n",
       " '<BOS> じっとしてて。 <EOS>',\n",
       " '<BOS> トムに電話して。 <EOS>',\n",
       " '<BOS> トムを呼んで。 <EOS>',\n",
       " '<BOS> 元気出して。 <EOS>',\n",
       " '<BOS> 元気を出せよ。 <EOS>',\n",
       " '<BOS> 元気出せよ。 <EOS>',\n",
       " '<BOS> 元気出しなよ。 <EOS>',\n",
       " '<BOS> 元気出して。 <EOS>',\n",
       " '<BOS> 元気出しなよ。 <EOS>',\n",
       " '<BOS> 頭を冷やせ。 <EOS>',\n",
       " '<BOS> 行くんじゃない。 <EOS>',\n",
       " '<BOS> 行かないで。 <EOS>',\n",
       " '<BOS> トムを探してきて。 <EOS>',\n",
       " '<BOS> トムを見つけて。 <EOS>',\n",
       " '<BOS> 向こうへ行け！ <EOS>',\n",
       " '<BOS> 床に伏せろ！ <EOS>',\n",
       " '<BOS> どっか行け。 <EOS>',\n",
       " '<BOS> 出て行け！ <EOS>',\n",
       " '<BOS> どっか行け。 <EOS>',\n",
       " '<BOS> 冷静に考えて見ろよ！ <EOS>',\n",
       " '<BOS> どうぞ、お先に！ <EOS>',\n",
       " '<BOS> どうぞお話し下さい。 <EOS>',\n",
       " '<BOS> どうぞ、お先に！ <EOS>',\n",
       " '<BOS> お疲れ様でした。 <EOS>',\n",
       " '<BOS> お疲れさまでした。 <EOS>',\n",
       " '<BOS> よくやった！ <EOS>',\n",
       " '<BOS> トムを捕まえろ。 <EOS>',\n",
       " '<BOS> 楽しんでね。 <EOS>',\n",
       " '<BOS> 楽しんできなさい。 <EOS>',\n",
       " '<BOS> 彼がやってみるんだ。 <EOS>',\n",
       " '<BOS> トムを助けてやって。 <EOS>',\n",
       " '<BOS> なんて可愛いんでしょう。 <EOS>',\n",
       " '<BOS> かわいい！ <EOS>',\n",
       " '<BOS> どのくらい深い？ <EOS>',\n",
       " '<BOS> 急ぎなさい。 <EOS>',\n",
       " '<BOS> さあ、急いで。 <EOS>',\n",
       " '<BOS> やった。 <EOS>',\n",
       " '<BOS> やってやった。 <EOS>',\n",
       " '<BOS> 忘れました。 <EOS>',\n",
       " '<BOS> 忘れた。 <EOS>',\n",
       " '<BOS> 了解。 <EOS>',\n",
       " '<BOS> 辞めます。 <EOS>',\n",
       " '<BOS> 私がそれを使います。 <EOS>',\n",
       " '<BOS> あくびをした。 <EOS>',\n",
       " '<BOS> 僕のおごりですよ。 <EOS>',\n",
       " '<BOS> 僕が払っとこう。 <EOS>',\n",
       " '<BOS> 私のおごりだ。 <EOS>',\n",
       " '<BOS> 私が払います。 <EOS>',\n",
       " '<BOS> 私が払いましょう。 <EOS>',\n",
       " '<BOS> 頑張ってみる。 <EOS>',\n",
       " '<BOS> トライします。 <EOS>',\n",
       " '<BOS> やってみる。 <EOS>',\n",
       " '<BOS> 僕は忙しい。 <EOS>',\n",
       " '<BOS> 私は忙しい。 <EOS>',\n",
       " '<BOS> 忙しいです。 <EOS>',\n",
       " '<BOS> 俺はクールだ。 <EOS>',\n",
       " '<BOS> 俺はいかしてる。 <EOS>',\n",
       " '<BOS> 私は公平だ。 <EOS>',\n",
       " '<BOS> 私は大丈夫です。 <EOS>',\n",
       " '<BOS> 私は元気です。 <EOS>',\n",
       " '<BOS> 私は暇だ。 <EOS>',\n",
       " '<BOS> 暇ですよ。 <EOS>',\n",
       " '<BOS> 私は自由の身だ。 <EOS>',\n",
       " '<BOS> 手は空いていますよ。 <EOS>',\n",
       " '<BOS> 時間はあります。 <EOS>',\n",
       " '<BOS> もう満腹です。 <EOS>',\n",
       " '<BOS> お腹がいっぱいです。 <EOS>',\n",
       " '<BOS> 道に迷ってしまった。 <EOS>',\n",
       " '<BOS> 私は貧乏です。 <EOS>',\n",
       " '<BOS> 病気です。 <EOS>',\n",
       " '<BOS> 私は背が高い。 <EOS>',\n",
       " '<BOS> 大丈夫ですよ。 <EOS>',\n",
       " '<BOS> 私は大丈夫です。 <EOS>',\n",
       " '<BOS> 私は元気です。 <EOS>',\n",
       " '<BOS> トムだ。 <EOS>',\n",
       " '<BOS> それは新しいです。 <EOS>',\n",
       " '<BOS> 立ち入りを禁ず。 <EOS>',\n",
       " '<BOS> 放っておけ。 <EOS>',\n",
       " '<BOS> 放っておきなさいよ。 <EOS>',\n",
       " '<BOS> やめておけ。 <EOS>',\n",
       " '<BOS> 行くよ。 <EOS>',\n",
       " '<BOS> さあ、行くぞ。 <EOS>',\n",
       " '<BOS> 危ない！ <EOS>',\n",
       " '<BOS> 私と結婚して。 <EOS>',\n",
       " '<BOS> はっきり言いなさい。 <EOS>',\n",
       " '<BOS> 立ちなさい。 <EOS>',\n",
       " '<BOS> 起立！ <EOS>',\n",
       " '<BOS> 立ちなさい。 <EOS>',\n",
       " '<BOS> 起立！ <EOS>',\n",
       " '<BOS> トムに教えて。 <EOS>',\n",
       " '<BOS> トムに伝えて。 <EOS>',\n",
       " '<BOS> すごいぞ！ <EOS>',\n",
       " '<BOS> 素晴らしい！ <EOS>',\n",
       " '<BOS> 彼らは勝った。 <EOS>',\n",
       " '<BOS> トムが来た。 <EOS>',\n",
       " '<BOS> トムは死んだ。 <EOS>',\n",
       " '<BOS> トムは落ちた。 <EOS>',\n",
       " '<BOS> トムは知った。 <EOS>',\n",
       " '<BOS> トムはさった。 <EOS>',\n",
       " '<BOS> トムは嘘をついた。 <EOS>',\n",
       " '<BOS> トムは嘘をつく。 <EOS>',\n",
       " '<BOS> トムが負けた。 <EOS>',\n",
       " '<BOS> トムは払った。 <EOS>',\n",
       " '<BOS> トムはやめた。 <EOS>',\n",
       " '<BOS> トムは泳いだ。 <EOS>',\n",
       " '<BOS> トムは涙を流した。 <EOS>',\n",
       " '<BOS> トムは泣きました。 <EOS>',\n",
       " '<BOS> トムは泣いた。 <EOS>',\n",
       " '<BOS> 遅すぎる。 <EOS>',\n",
       " '<BOS> 信じてくれよ。 <EOS>',\n",
       " '<BOS> 信用してください。 <EOS>',\n",
       " '<BOS> 精一杯やってみなさい。 <EOS>',\n",
       " '<BOS> これ使って。 <EOS>',\n",
       " '<BOS> トムに警告します。 <EOS>',\n",
       " '<BOS> トムに警告する。 <EOS>',\n",
       " '<BOS> トムに警告してください。 <EOS>',\n",
       " '<BOS> トムに警告しなさい。 <EOS>',\n",
       " '<BOS> 意見が一致している。 <EOS>',\n",
       " '<BOS> 何のために？ <EOS>',\n",
       " '<BOS> 何に使うの？ <EOS>',\n",
       " '<BOS> 誰が来た？ <EOS>',\n",
       " '<BOS> 誰が来ましたか？ <EOS>',\n",
       " '<BOS> 誰が死んだの？ <EOS>',\n",
       " '<BOS> 誰がやめるの？ <EOS>',\n",
       " '<BOS> お先にどうぞ。 <EOS>',\n",
       " '<BOS> 鳥は飛ぶ。 <EOS>',\n",
       " '<BOS> 家に電話して！ <EOS>',\n",
       " '<BOS> 落ち着いて。 <EOS>',\n",
       " '<BOS> 落ちついて。 <EOS>',\n",
       " '<BOS> 落ち着けよ！ <EOS>',\n",
       " '<BOS> 落ち着け！ <EOS>',\n",
       " '<BOS> 落ち着いて！ <EOS>',\n",
       " '<BOS> 落ち着けよ。 <EOS>',\n",
       " '<BOS> 落ち着いて。 <EOS>',\n",
       " '<BOS> 落ちつけよ。 <EOS>',\n",
       " '<BOS> 落ちつきな。 <EOS>',\n",
       " '<BOS> 落ちついて。 <EOS>',\n",
       " '<BOS> 頭を冷やせよ。 <EOS>',\n",
       " '<BOS> 頭を冷やせ。 <EOS>',\n",
       " '<BOS> 落ち着け！ <EOS>',\n",
       " '<BOS> 落ち着いて！ <EOS>',\n",
       " '<BOS> 彼を捕まえて。 <EOS>',\n",
       " '<BOS> 彼を捕まえろ。 <EOS>',\n",
       " '<BOS> 落ち着いて。 <EOS>',\n",
       " '<BOS> 戻っておいで。 <EOS>',\n",
       " '<BOS> ちょっと来て。 <EOS>',\n",
       " '<BOS> こちらに来なさい。 <EOS>',\n",
       " '<BOS> こっちへ来なさい! <EOS>',\n",
       " '<BOS> ここへ来なさい！ <EOS>',\n",
       " '<BOS> こっちに来て。 <EOS>',\n",
       " '<BOS> こっちに来いよ。 <EOS>',\n",
       " '<BOS> こっちへおいで。 <EOS>',\n",
       " '<BOS> こっちおいで。 <EOS>',\n",
       " '<BOS> 家に来て。 <EOS>',\n",
       " '<BOS> 家に来いよ。 <EOS>',\n",
       " '<BOS> 帰ってきなさい。 <EOS>',\n",
       " '<BOS> 帰ってこい。 <EOS>',\n",
       " '<BOS> 家に戻ってきなさい。 <EOS>',\n",
       " '<BOS> 私の家に来て下さい。 <EOS>',\n",
       " '<BOS> 家においでよ。 <EOS>',\n",
       " '<BOS> 遊びに来いよ！ <EOS>',\n",
       " '<BOS> 家に来てよ！ <EOS>',\n",
       " '<BOS> すぐ来て。 <EOS>',\n",
       " '<BOS> 落ち着いて。 <EOS>',\n",
       " '<BOS> 頭を冷やせ。 <EOS>',\n",
       " '<BOS> 勝った？ <EOS>',\n",
       " '<BOS> 犬が吠える。 <EOS>',\n",
       " '<BOS> 聞かないでくれ。 <EOS>',\n",
       " '<BOS> 泣かないで。 <EOS>',\n",
       " '<BOS> 死なないで。 <EOS>',\n",
       " '<BOS> 嘘をつくな。 <EOS>',\n",
       " '<BOS> 失礼しました。 <EOS>',\n",
       " '<BOS> あのー、失礼ですが。 <EOS>',\n",
       " '<BOS> すみません。 <EOS>',\n",
       " '<BOS> もう一度お願いします。 <EOS>',\n",
       " '<BOS> すごいぞ！ <EOS>',\n",
       " '<BOS> お見事！ <EOS>',\n",
       " '<BOS> 素晴らしい！ <EOS>',\n",
       " '<BOS> 私についてきて。 <EOS>',\n",
       " '<BOS> ついてきて。 <EOS>',\n",
       " '<BOS> 忘れて。 <EOS>',\n",
       " '<BOS> さあ行った、行った。 <EOS>',\n",
       " '<BOS> もう寝なさい。 <EOS>',\n",
       " '<BOS> 元気でね。 <EOS>',\n",
       " '<BOS> 頑張れよ。 <EOS>',\n",
       " '<BOS> 触るな！ <EOS>',\n",
       " '<BOS> 彼は年を取っている。 <EOS>',\n",
       " '<BOS> 彼はＤＪです。 <EOS>',\n",
       " '<BOS> 彼は尻が重い。 <EOS>',\n",
       " '<BOS> ああ恐い！ <EOS>',\n",
       " '<BOS> 景気はどうですか？ <EOS>',\n",
       " '<BOS> トムの機嫌をとれ。 <EOS>',\n",
       " '<BOS> 忙しいです。 <EOS>',\n",
       " '<BOS> 私は落ち着いています。 <EOS>',\n",
       " '<BOS> お腹いっぱいだ。 <EOS>',\n",
       " '<BOS> 確かだよ。 <EOS>',\n",
       " '<BOS> そのことを確信している。 <EOS>',\n",
       " '<BOS> 私は背が高い。 <EOS>',\n",
       " '<BOS> 私は走ることができる。 <EOS>',\n",
       " '<BOS> 私はスキーの仕方を知っています。 <EOS>',\n",
       " '<BOS> 私は気を失いました。 <EOS>',\n",
       " '<BOS> 私の負けだ。 <EOS>',\n",
       " '<BOS> 降参します。 <EOS>',\n",
       " '<BOS> お手上げだ。 <EOS>',\n",
       " '<BOS> 私は怒ったんだ。 <EOS>',\n",
       " '<BOS> 楽しかった。 <EOS>',\n",
       " '<BOS> 持っています。 <EOS>',\n",
       " '<BOS> トムを叩いた。 <EOS>',\n",
       " '<BOS> そうだといいけど。 <EOS>',\n",
       " '<BOS> 私もそう願います。 <EOS>',\n",
       " '<BOS> 私は笑ってしまった。 <EOS>',\n",
       " '<BOS> 本気だよ。 <EOS>',\n",
       " '<BOS> 本気で言ってるんです。 <EOS>',\n",
       " '<BOS> 私は彼に会った。 <EOS>',\n",
       " '<BOS> 行かなくちゃ。 <EOS>',\n",
       " '<BOS> 約束するよ。 <EOS>',\n",
       " '<BOS> 僕はリラックスした。 <EOS>',\n",
       " '<BOS> ダメだって言ったでしょ。 <EOS>',\n",
       " '<BOS> 違うってば。 <EOS>',\n",
       " '<BOS> そう言っておいたはずだ。 <EOS>',\n",
       " '<BOS> 私は彼に会った。 <EOS>',\n",
       " '<BOS> 彼を見た。 <EOS>',\n",
       " '<BOS> トムが見える。 <EOS>',\n",
       " '<BOS> これが欲しい。 <EOS>',\n",
       " '<BOS> 私は怒り狂っていたんだ。 <EOS>',\n",
       " '<BOS> 行くよ。 <EOS>',\n",
       " '<BOS> 私が行きます。 <EOS>',\n",
       " '<BOS> 私は同意するだろう。 <EOS>',\n",
       " '<BOS> お手伝いしますよ。 <EOS>',\n",
       " '<BOS> 私は手伝うよ。 <EOS>',\n",
       " '<BOS> 手伝うよ。 <EOS>',\n",
       " '<BOS> 僕、男だよ。 <EOS>',\n",
       " '<BOS> 私は警官だ。 <EOS>',\n",
       " '<BOS> 一人だ。 <EOS>',\n",
       " '<BOS> 私は一人だ。 <EOS>',\n",
       " '<BOS> 起きてるよ。 <EOS>',\n",
       " '<BOS> 退屈しちゃったよ。 <EOS>',\n",
       " '<BOS> 私は勇敢だ。 <EOS>',\n",
       " '<BOS> 文無しなんだ。 <EOS>',\n",
       " '<BOS> 金欠なんだ。 <EOS>',\n",
       " '<BOS> 私は潔白だ。 <EOS>',\n",
       " '<BOS> 私は清潔だ。 <EOS>',\n",
       " '<BOS> くらくらする。 <EOS>',\n",
       " '<BOS> 酔った。 <EOS>',\n",
       " '<BOS> 酔った。 <EOS>',\n",
       " '<BOS> もう死にそう。 <EOS>',\n",
       " '<BOS> 早かった。 <EOS>',\n",
       " '<BOS> 私が一番。 <EOS>',\n",
       " '<BOS> 私は几帳面なんだ。 <EOS>',\n",
       " '<BOS> 私は細かいんだ。 <EOS>',\n",
       " '<BOS> 私は幸福です。 <EOS>',\n",
       " '<BOS> 私は幸せだ。 <EOS>',\n",
       " '<BOS> 私は幸せです。 <EOS>',\n",
       " '<BOS> 私はついている。 <EOS>',\n",
       " '<BOS> 準備ができました。 <EOS>',\n",
       " '<BOS> 俺って、頭いい！ <EOS>',\n",
       " '<BOS> 私って冴えてる！ <EOS>',\n",
       " '<BOS> 私は酔っていない。 <EOS>',\n",
       " '<BOS> 悪かった。 <EOS>',\n",
       " '<BOS> どうも失礼。 <EOS>',\n",
       " '<BOS> 御免なさい。 <EOS>',\n",
       " '<BOS> すみません。 <EOS>',\n",
       " '<BOS> 疲れているんだ。 <EOS>',\n",
       " '<BOS> 疲れました。 <EOS>',\n",
       " '<BOS> 疲れたよ。 <EOS>',\n",
       " '<BOS> 疲れたなあ。 <EOS>',\n",
       " '<BOS> 私は疲れた。 <EOS>',\n",
       " '<BOS> 僕は若い。 <EOS>',\n",
       " '<BOS> 彼はトムですか？ <EOS>',\n",
       " '<BOS> そこって遠いですか？ <EOS>',\n",
       " '<BOS> 超臭いよ。 <EOS>',\n",
       " '<BOS> 動いた！ <EOS>',\n",
       " '<BOS> うまく行った！ <EOS>',\n",
       " '<BOS> ３時半です。 <EOS>',\n",
       " '<BOS> ７時４５分です。 <EOS>',\n",
       " '<BOS> ９時１５分です。 <EOS>',\n",
       " '<BOS> 寒い。 <EOS>',\n",
       " '<BOS> 寒っ！ <EOS>',\n",
       " '<BOS> カッコいい！ <EOS>',\n",
       " '<BOS> 楽勝だよ。 <EOS>',\n",
       " '<BOS> 無料です。 <EOS>',\n",
       " '<BOS> それは無料です。 <EOS>',\n",
       " '<BOS> もう遅いわよ。 <EOS>',\n",
       " '<BOS> それ、私の。 <EOS>',\n",
       " '<BOS> それ、私のです。 <EOS>',\n",
       " '<BOS> 大丈夫、大丈夫。 <EOS>',\n",
       " '<BOS> それが仕事です。 <EOS>',\n",
       " '<BOS> 飛び降りろ！ <EOS>',\n",
       " '<BOS> 離れてて。 <EOS>',\n",
       " '<BOS> 下がってて。 <EOS>',\n",
       " '<BOS> あったかくしてなさい。 <EOS>',\n",
       " '<BOS> 私に行かせてください。 <EOS>',\n",
       " '<BOS> 中に入れてよ。 <EOS>',\n",
       " '<BOS> 中に入れて。 <EOS>',\n",
       " '<BOS> 私も参加させてください。 <EOS>',\n",
       " '<BOS> 私も入れてください。 <EOS>',\n",
       " '<BOS> 中に入れてください。 <EOS>',\n",
       " '<BOS> やってみようよ。 <EOS>',\n",
       " '<BOS> よく聞きなさい。 <EOS>',\n",
       " '<BOS> 後ろを見ろ。 <EOS>',\n",
       " '<BOS> 食べてもいいですか？ <EOS>',\n",
       " '<BOS> もちろんだよ！ <EOS>',\n",
       " '<BOS> もちろん！ <EOS>',\n",
       " '<BOS> もちろん。 <EOS>',\n",
       " '<BOS> もちろんだよ！ <EOS>',\n",
       " '<BOS> もちろんさ。 <EOS>',\n",
       " '<BOS> もちろん！ <EOS>',\n",
       " '<BOS> もちろん。 <EOS>',\n",
       " '<BOS> 撃て！ <EOS>',\n",
       " '<BOS> もう一度お願いします。 <EOS>',\n",
       " '<BOS> 静かに！ <EOS>',\n",
       " '<BOS> 静かにしなさい。 <EOS>',\n",
       " '<BOS> 静かに！ <EOS>',\n",
       " '<BOS> 静かにしなさい。 <EOS>',\n",
       " '<BOS> これを読みなさい。 <EOS>',\n",
       " '<BOS> これを読んで。 <EOS>',\n",
       " '<BOS> 「アー」といってください。 <EOS>',\n",
       " '<BOS> 前述参照のこと。 <EOS>',\n",
       " '<BOS> 本気？ <EOS>',\n",
       " '<BOS> 彼女は泣いた。 <EOS>',\n",
       " '<BOS> 彼女は試した。 <EOS>',\n",
       " '<BOS> 彼女はやってみた。 <EOS>',\n",
       " '<BOS> ここでサインして。 <EOS>',\n",
       " '<BOS> そこにお座り。 <EOS>',\n",
       " '<BOS> 近づくな！ <EOS>',\n",
       " '<BOS> どいてろ。 <EOS>',\n",
       " '<BOS> 落ち着いて。 <EOS>',\n",
       " '<BOS> 落ちついて。 <EOS>',\n",
       " '<BOS> 静かにしてなさい。 <EOS>',\n",
       " '<BOS> 下がって。 <EOS>',\n",
       " '<BOS> やめなさい。 <EOS>',\n",
       " '<BOS> やめろ！ <EOS>',\n",
       " '<BOS> やめなさい。 <EOS>',\n",
       " '<BOS> やめろ！ <EOS>',\n",
       " '<BOS> 用心しなさい。 <EOS>',\n",
       " '<BOS> 気を付けてね。 <EOS>',\n",
       " '<BOS> お気をつけて。 <EOS>',\n",
       " '<BOS> 気をつけて！ <EOS>',\n",
       " '<BOS> 用心しなさい。 <EOS>',\n",
       " '<BOS> 気を付けてね。 <EOS>',\n",
       " '<BOS> お体を大切に。 <EOS>',\n",
       " '<BOS> お気をつけて。 <EOS>',\n",
       " '<BOS> 気をつけて！ <EOS>',\n",
       " '<BOS> 私のをどうぞ。 <EOS>',\n",
       " '<BOS> これ使って。 <EOS>',\n",
       " '<BOS> これにしなよ。 <EOS>',\n",
       " '<BOS> ありがとうございます！ <EOS>',\n",
       " '<BOS> お疲れさまでした。 <EOS>',\n",
       " '<BOS> ありがとう。 <EOS>',\n",
       " '<BOS> それでいいよ。 <EOS>',\n",
       " '<BOS> 図星です。 <EOS>',\n",
       " '<BOS> そういうこと。 <EOS>',\n",
       " '<BOS> 彼らは去った。 <EOS>',\n",
       " '<BOS> 彼らは嘘をついた。 <EOS>',\n",
       " '<BOS> 彼らは負けた。 <EOS>',\n",
       " '<BOS> 彼らは泳いだ。 <EOS>',\n",
       " '<BOS> 時間終了。 <EOS>',\n",
       " '<BOS> トムは料理する。 <EOS>',\n",
       " '<BOS> トムは涙を流した。 <EOS>',\n",
       " '<BOS> トムは泣いていた。 <EOS>',\n",
       " '<BOS> トムは飲んだ。 <EOS>',\n",
       " '<BOS> トムは運転した。 <EOS>',\n",
       " '<BOS> トムは編み物をする。 <EOS>',\n",
       " '<BOS> トムは知っている。 <EOS>',\n",
       " '<BOS> トムは動いた。 <EOS>',\n",
       " '<BOS> トムは引っ越した。 <EOS>',\n",
       " '<BOS> トムは寝ていた。 <EOS>',\n",
       " '<BOS> トムは眠っていた。 <EOS>',\n",
       " '<BOS> トムは話した。 <EOS>',\n",
       " '<BOS> トムは立った。 <EOS>',\n",
       " '<BOS> トムは挑戦した。 <EOS>',\n",
       " '<BOS> トムはやってみた。 <EOS>',\n",
       " '<BOS> トムは挑戦する。 <EOS>',\n",
       " '<BOS> トムは手を振った。 <EOS>',\n",
       " '<BOS> トムは手をふった。 <EOS>',\n",
       " '<BOS> もう１度やってみなさい。 <EOS>',\n",
       " '<BOS> もう一度やってみて。 <EOS>',\n",
       " '<BOS> もう一回やってみて。 <EOS>',\n",
       " '<BOS> 左に曲がって。 <EOS>',\n",
       " '<BOS> ここで待って。 <EOS>',\n",
       " '<BOS> 危ない！ <EOS>',\n",
       " '<BOS> 気をつけて！ <EOS>',\n",
       " '<BOS> 成功だ！ <EOS>',\n",
       " '<BOS> やった。 <EOS>',\n",
       " '<BOS> 忘れた。 <EOS>',\n",
       " '<BOS> 僕らは話した。 <EOS>',\n",
       " '<BOS> 僕らは待った。 <EOS>',\n",
       " '<BOS> 私たちは男です。 <EOS>',\n",
       " '<BOS> 勝った！ <EOS>',\n",
       " '<BOS> お見事！ <EOS>',\n",
       " '<BOS> よくやった！ <EOS>',\n",
       " '<BOS> 上出来！ <EOS>',\n",
       " '<BOS> お見事！ <EOS>',\n",
       " '<BOS> よくやった！ <EOS>',\n",
       " '<BOS> 変わりない？ <EOS>',\n",
       " '<BOS> 何が起こったんだ？ <EOS>',\n",
       " '<BOS> 知るもんか。 <EOS>',\n",
       " '<BOS> 誰？ <EOS>',\n",
       " '<BOS> どなた？ <EOS>',\n",
       " '<BOS> どなたさまでしょうか。 <EOS>',\n",
       " '<BOS> 誰にも分からないよ。 <EOS>',\n",
       " '<BOS> 誰が行くの？ <EOS>',\n",
       " '<BOS> トムって誰？ <EOS>',\n",
       " '<BOS> 彼女は誰ですか。 <EOS>',\n",
       " '<BOS> すごいぞ！ <EOS>',\n",
       " '<BOS> 素晴らしい！ <EOS>',\n",
       " '<BOS> トムに手紙を書きなよ。 <EOS>',\n",
       " '<BOS> ご乗車願います！ <EOS>',\n",
       " '<BOS> 何言っているか分かる？ <EOS>',\n",
       " '<BOS> 私の言ってること、わかります？ <EOS>',\n",
       " '<BOS> 俺、クビですか？ <EOS>',\n",
       " '<BOS> 私、正しい？ <EOS>',\n",
       " '<BOS> 俺は間違っているのか。 <EOS>',\n",
       " '<BOS> 大丈夫ですか？ <EOS>',\n",
       " '<BOS> 大丈夫？ <EOS>',\n",
       " '<BOS> いる? <EOS>',\n",
       " '<BOS> 気をつけて！ <EOS>',\n",
       " '<BOS> 用心しなさい。 <EOS>',\n",
       " '<BOS> 気を付けてね。 <EOS>',\n",
       " '<BOS> 気をつけて！ <EOS>',\n",
       " '<BOS> 時間に遅れないで。 <EOS>',\n",
       " '<BOS> 辛抱しなさい。 <EOS>',\n",
       " '<BOS> ふざけないで。 <EOS>',\n",
       " '<BOS> 真面目におやり。 <EOS>',\n",
       " '<BOS> 鳥は歌います。 <EOS>',\n",
       " '<BOS> 鳥が囀る。 <EOS>',\n",
       " '<BOS> 鳥は鳴く。 <EOS>',\n",
       " '<BOS> 乾杯！ <EOS>',\n",
       " '<BOS> 私も行ってもいい？ <EOS>',\n",
       " '<BOS> 手伝おうか。 <EOS>',\n",
       " '<BOS> 手伝おうか？ <EOS>',\n",
       " '<BOS> これ運んで。 <EOS>',\n",
       " '<BOS> 一つ選んで。 <EOS>',\n",
       " '<BOS> また来てね。 <EOS>',\n",
       " '<BOS> さあ、一緒に来いよ。 <EOS>',\n",
       " '<BOS> いっしょに来なさい。 <EOS>',\n",
       " '<BOS> 私達と一緒に来なさい。 <EOS>',\n",
       " '<BOS> 入っておいでよ。 <EOS>',\n",
       " '<BOS> さあ、入って入って。 <EOS>',\n",
       " '<BOS> 入っておいでよ。 <EOS>',\n",
       " '<BOS> 早く来い。 <EOS>',\n",
       " '<BOS> 早く来なさい。 <EOS>',\n",
       " '<BOS> 早くいらっしゃい。 <EOS>',\n",
       " '<BOS> 早くおいで。 <EOS>',\n",
       " '<BOS> やめなさい。 <EOS>',\n",
       " '<BOS> やめろ！ <EOS>',\n",
       " '<BOS> いい加減にしろよ。 <EOS>',\n",
       " '<BOS> いいかげんにして。 <EOS>',\n",
       " '<BOS> 混ぜて。 <EOS>',\n",
       " '<BOS> もちろんだよ！ <EOS>',\n",
       " '<BOS> もちろん！ <EOS>',\n",
       " '<BOS> トムは行った？ <EOS>',\n",
       " '<BOS> 勝った？ <EOS>',\n",
       " '<BOS> さあどうぞお入りください。 <EOS>',\n",
       " '<BOS> 入って。 <EOS>',\n",
       " '<BOS> スキーは滑る？ <EOS>',\n",
       " '<BOS> 来ないで。 <EOS>',\n",
       " '<BOS> 見ないで。 <EOS>',\n",
       " '<BOS> 動かないで！ <EOS>',\n",
       " '<BOS> じっとして！ <EOS>',\n",
       " '<BOS> 動くな！ <EOS>',\n",
       " '<BOS> 動かないで！ <EOS>',\n",
       " '<BOS> 動かないで。 <EOS>',\n",
       " '<BOS> 押すなよ。 <EOS>',\n",
       " '<BOS> 話しかけるな。 <EOS>',\n",
       " '<BOS> 黙っていなさい。 <EOS>',\n",
       " '<BOS> 黙っていなさい。 <EOS>',\n",
       " '<BOS> 待つな。 <EOS>',\n",
       " '<BOS> ゆっくり食べて。 <EOS>',\n",
       " '<BOS> 満タンにしてください。 <EOS>',\n",
       " '<BOS> 仕事を見つけろ。 <EOS>',\n",
       " '<BOS> 火は燃える。 <EOS>',\n",
       " '<BOS> トムに従え。 <EOS>',\n",
       " '<BOS> 彼の事は忘れなさい。 <EOS>',\n",
       " '<BOS> 許して。 <EOS>',\n",
       " '<BOS> お許しを。 <EOS>',\n",
       " '<BOS> さあ行った、行った。 <EOS>',\n",
       " '<BOS> ベッドへいけ。 <EOS>',\n",
       " '<BOS> 諦めろ。 <EOS>',\n",
       " '<BOS> 帰りなさい。 <EOS>',\n",
       " '<BOS> トムに会ってきて。 <EOS>',\n",
       " '<BOS> 仕事に行きなさい。 <EOS>',\n",
       " '<BOS> 洗ってきて。 <EOS>',\n",
       " '<BOS> 神は存在する。 <EOS>',\n",
       " '<BOS> おやすみなさい。 <EOS>',\n",
       " '<BOS> 彼は外食した。 <EOS>',\n",
       " '<BOS> 彼は降参した。 <EOS>',\n",
       " '<BOS> 彼は降参した。 <EOS>',\n",
       " '<BOS> 彼は電話を切った。 <EOS>',\n",
       " '<BOS> 彼はＤＪです。 <EOS>',\n",
       " '<BOS> 優しい人です。 <EOS>',\n",
       " '<BOS> いい人です。 <EOS>',\n",
       " '<BOS> 彼は親切な人です。 <EOS>',\n",
       " '<BOS> 彼は尻が重い。 <EOS>',\n",
       " '<BOS> 彼はいい人です。 <EOS>',\n",
       " '<BOS> いい人です。 <EOS>',\n",
       " '<BOS> 彼は病気です。 <EOS>',\n",
       " '<BOS> 彼は成功した。 <EOS>',\n",
       " '<BOS> 彼はうそをついている。 <EOS>',\n",
       " '<BOS> 彼は嘘をついている。 <EOS>',\n",
       " '<BOS> 利口だね。 <EOS>',\n",
       " '<BOS> 彼は頭がいい。 <EOS>',\n",
       " '<BOS> 温めて。 <EOS>',\n",
       " '<BOS> 上がるの手伝って。 <EOS>',\n",
       " '<BOS> 起き上がるの手伝って。 <EOS>',\n",
       " '<BOS> 立ち上がるの手伝って。 <EOS>',\n",
       " '<BOS> あっ、来た来た。 <EOS>',\n",
       " '<BOS> はいどうぞ。 <EOS>',\n",
       " '<BOS> ほら、ここにあるよ。 <EOS>',\n",
       " '<BOS> さあ、行くぞ。 <EOS>',\n",
       " '<BOS> 落ちつきな。 <EOS>',\n",
       " '<BOS> じっとしてて。 <EOS>',\n",
       " '<BOS> 賢い！ <EOS>',\n",
       " '<BOS> かわいい！ <EOS>',\n",
       " '<BOS> 悲惨！ <EOS>',\n",
       " '<BOS> 仕事はどう？ <EOS>',\n",
       " '<BOS> どう、仕事は？ <EOS>',\n",
       " '<BOS> 急いで戻れ。 <EOS>',\n",
       " '<BOS> 早く家に帰って来なさい。 <EOS>',\n",
       " '<BOS> それは認める。 <EOS>',\n",
       " '<BOS> 僕、男だよ。 <EOS>',\n",
       " '<BOS> 俺は人間だ。 <EOS>',\n",
       " '<BOS> 私は幸福です。 <EOS>',\n",
       " '<BOS> 私は幸せだ。 <EOS>',\n",
       " '<BOS> 私は幸せです。 <EOS>',\n",
       " '<BOS> 疲れました。 <EOS>',\n",
       " '<BOS> 疲れたなあ。 <EOS>',\n",
       " '<BOS> 私が壊した。 <EOS>',\n",
       " '<BOS> 私が作ったんです。 <EOS>',\n",
       " '<BOS> 歌える。 <EOS>',\n",
       " '<BOS> 歌が歌える。 <EOS>',\n",
       " '<BOS> 私は残れます。 <EOS>',\n",
       " '<BOS> 私は泳げます。 <EOS>',\n",
       " '<BOS> 私は泳ぐことが出来ます。 <EOS>',\n",
       " '<BOS> 待てます。 <EOS>',\n",
       " '<BOS> 歩ける。 <EOS>',\n",
       " '<BOS> 私は行かれません。 <EOS>',\n",
       " '<BOS> 私は行けません。 <EOS>',\n",
       " '<BOS> 私はそうは思いません。 <EOS>',\n",
       " '<BOS> そうは思いません。 <EOS>',\n",
       " '<BOS> 反対 <EOS>',\n",
       " '<BOS> 私はそれを疑った。 <EOS>',\n",
       " '<BOS> ここで食べます。 <EOS>',\n",
       " '<BOS> 私はここで食べます。 <EOS>',\n",
       " '<BOS> トムが羨ましいよ。 <EOS>',\n",
       " '<BOS> あの子が羨ましい。 <EOS>',\n",
       " '<BOS> 羨ましい！ <EOS>',\n",
       " '<BOS> 羨ましい！ <EOS>',\n",
       " '<BOS> いいなあ。 <EOS>',\n",
       " '<BOS> 羨ましい！ <EOS>',\n",
       " '<BOS> 気分が悪い。 <EOS>',\n",
       " '<BOS> 私も年をとったなあ。 <EOS>',\n",
       " '<BOS> 見つかった。 <EOS>',\n",
       " '<BOS> 見つけた！ <EOS>',\n",
       " '<BOS> 忙しくなった。 <EOS>',\n",
       " '<BOS> 道に迷ってしまいました。 <EOS>',\n",
       " '<BOS> 悪酔いしました。 <EOS>',\n",
       " '<BOS> 私はトムが嫌いだ。 <EOS>',\n",
       " '<BOS> 持っています。 <EOS>',\n",
       " '<BOS> トムは知っている。 <EOS>',\n",
       " '<BOS> 彼女を知っている。 <EOS>',\n",
       " '<BOS> トムは好きだ。 <EOS>',\n",
       " '<BOS> トムの事は気に入っている。 <EOS>',\n",
       " '<BOS> 彼が好きです。 <EOS>',\n",
       " '<BOS> 私はお茶が好きです。 <EOS>',\n",
       " '<BOS> 君が好きだ。 <EOS>',\n",
       " '<BOS> 気に入りました。 <EOS>',\n",
       " '<BOS> それ、いいね。 <EOS>',\n",
       " '<BOS> 彼女に恋している。 <EOS>',\n",
       " '<BOS> 彼女のことが好きだ。 <EOS>',\n",
       " '<BOS> 彼女のことが大好きです。 <EOS>',\n",
       " '<BOS> 愛してる。 <EOS>',\n",
       " '<BOS> 大好きだよ！ <EOS>',\n",
       " '<BOS> 君が好きだ。 <EOS>',\n",
       " '<BOS> 私はあなたを愛しています。 <EOS>',\n",
       " '<BOS> トムが居たらと思う。 <EOS>',\n",
       " '<BOS> 会えなくて淋しい。 <EOS>',\n",
       " '<BOS> 君がいなくて寂しいよ。 <EOS>',\n",
       " '<BOS> 走ったほうがよさそうだ。 <EOS>',\n",
       " '<BOS> トムが必要だ。 <EOS>',\n",
       " '<BOS> 私にはトムが必要です。 <EOS>',\n",
       " '<BOS> 君が必要だ。 <EOS>',\n",
       " '<BOS> あなたが必要なんです。 <EOS>',\n",
       " '<BOS> パニクったわ。 <EOS>',\n",
       " '<BOS> 私は約束した。 <EOS>',\n",
       " '<BOS> 私はそう思います。 <EOS>',\n",
       " '<BOS> そう思いますよ。 <EOS>',\n",
       " '<BOS> そう思います。 <EOS>',\n",
       " '<BOS> 君が欲しい。 <EOS>',\n",
       " '<BOS> 迷っていた。 <EOS>',\n",
       " '<BOS> 私は無礼だった。 <EOS>',\n",
       " '<BOS> 撃たれたんです。 <EOS>',\n",
       " '<BOS> 私は弱かった。 <EOS>',\n",
       " '<BOS> トライします。 <EOS>',\n",
       " '<BOS> やってみる。 <EOS>',\n",
       " '<BOS> 私は運動する。 <EOS>',\n",
       " '<BOS> 運動します。 <EOS>',\n",
       " '<BOS> 同意すると思うよ。 <EOS>',\n",
       " '<BOS> 大丈夫です。 <EOS>',\n",
       " '<BOS> 僕がやります。 <EOS>',\n",
       " '<BOS> 私がちゃんとやりますから。 <EOS>',\n",
       " '<BOS> 私がやります。 <EOS>',\n",
       " '<BOS> 私が中に入る。 <EOS>',\n",
       " '<BOS> 私は今30歳です。 <EOS>',\n",
       " '<BOS> 私は双子です。 <EOS>',\n",
       " '<BOS> 楽しんでるよ。 <EOS>',\n",
       " '<BOS> 私は先入観に縛られている。 <EOS>',\n",
       " '<BOS> 私は公平ではない。 <EOS>',\n",
       " '<BOS> 今、行くわ。 <EOS>',\n",
       " '<BOS> すぐ参ります。 <EOS>',\n",
       " '<BOS> いま行くよ。 <EOS>',\n",
       " '<BOS> 私は単刀直入なんです。 <EOS>',\n",
       " '<BOS> 今食事中。 <EOS>',\n",
       " '<BOS> 賛成。 <EOS>',\n",
       " '<BOS> ほんとだってば。 <EOS>',\n",
       " '<BOS> おなか空いた！ <EOS>',\n",
       " '<BOS> ああ、お腹が空いた。 <EOS>',\n",
       " '<BOS> お腹がすいた。 <EOS>',\n",
       " '<BOS> 腹が減った。 <EOS>',\n",
       " '<BOS> お腹が減った。 <EOS>',\n",
       " '<BOS> おなか空いた！ <EOS>',\n",
       " '<BOS> おなかペコペコだ。 <EOS>',\n",
       " '<BOS> お腹が減った。 <EOS>',\n",
       " '<BOS> 冗談だよ。 <EOS>',\n",
       " '<BOS> 淋しいです。 <EOS>',\n",
       " '<BOS> 疲れたなあ。 <EOS>',\n",
       " '<BOS> 私、怖い！ <EOS>',\n",
       " '<BOS> 独身です。 <EOS>',\n",
       " '<BOS> 眠い！ <EOS>',\n",
       " '<BOS> 眠い！ <EOS>',\n",
       " '<BOS> あー、眠い。 <EOS>',\n",
       " '<BOS> 僕はすごく太ってる。 <EOS>',\n",
       " '<BOS> 12歳です。 <EOS>',\n",
       " '<BOS> 食べた <EOS>',\n",
       " '<BOS> トムのことなど気にするな。 <EOS>',\n",
       " '<BOS> トム怒ってるかな？ <EOS>',\n",
       " '<BOS> 彼は忙しいですか。 <EOS>',\n",
       " '<BOS> 彼は背が高いですか。 <EOS>',\n",
       " '<BOS> 無料なのですか。 <EOS>',\n",
       " '<BOS> ただなの？ <EOS>',\n",
       " '<BOS> それ本当？ <EOS>',\n",
       " '<BOS> そうなんですか？ <EOS>',\n",
       " '<BOS> そうなの？ <EOS>',\n",
       " '<BOS> よくあることだよ。 <EOS>',\n",
       " '<BOS> 寒っ！ <EOS>',\n",
       " '<BOS> 空っぽだ。 <EOS>',\n",
       " '<BOS> 変なの！ <EOS>',\n",
       " '<BOS> 俺のＣＤじゃねえか。 <EOS>',\n",
       " '<BOS> それは私のCDです。 <EOS>',\n",
       " '<BOS> 僕のおごりですよ。 <EOS>',\n",
       " '<BOS> 私のおごりだ。 <EOS>',\n",
       " '<BOS> 妙だな。 <EOS>',\n",
       " '<BOS> 気色悪いー！ <EOS>',\n",
       " '<BOS> 風が強いな。 <EOS>',\n",
       " '<BOS> いいからやれよ。 <EOS>',\n",
       " '<BOS> とにかく落ち着いて。 <EOS>',\n",
       " '<BOS> そのまま続けて。 <EOS>',\n",
       " '<BOS> その調子で続けて。 <EOS>',\n",
       " '<BOS> その調子でがんばって。 <EOS>',\n",
       " '<BOS> 静かにしていなさい。 <EOS>',\n",
       " '<BOS> 静かにしていなさい。 <EOS>',\n",
       " '<BOS> じっとしてて。 <EOS>',\n",
       " '<BOS> 寄りかかっていいよ。 <EOS>',\n",
       " '<BOS> 当てにしていいよ。 <EOS>',\n",
       " '<BOS> トムを入れてあげて。 <EOS>',\n",
       " '<BOS> 中に入れてあげて。 <EOS>',\n",
       " '<BOS> お入り頂きなさい。 <EOS>',\n",
       " '<BOS> 中に入ってもらって。 <EOS>',\n",
       " '<BOS> 死なせてくれ。 <EOS>',\n",
       " '<BOS> 出してくれ。 <EOS>',\n",
       " '<BOS> 出してくれ。 <EOS>',\n",
       " '<BOS> 払わせてください。 <EOS>',\n",
       " '<BOS> 私が払いましょう。 <EOS>',\n",
       " '<BOS> 見せて。 <EOS>',\n",
       " '<BOS> どれどれ。 <EOS>',\n",
       " '<BOS> 私にやらせて。 <EOS>',\n",
       " '<BOS> お祈りしましょう。 <EOS>',\n",
       " '<BOS> さあ歌おう。 <EOS>',\n",
       " '<BOS> さあ泳ごう。 <EOS>',\n",
       " '<BOS> 気楽にいけよ。 <EOS>',\n",
       " '<BOS> これ見て。 <EOS>',\n",
       " '<BOS> 私を見なさい。 <EOS>',\n",
       " '<BOS> 私を見て。 <EOS>',\n",
       " '<BOS> 心配するな。 <EOS>',\n",
       " '<BOS> 気にするな。 <EOS>',\n",
       " '<BOS> 何でもない。 <EOS>',\n",
       " '<BOS> 問題ないよ。 <EOS>',\n",
       " '<BOS> 大丈夫ですよ。 <EOS>',\n",
       " '<BOS> 問題ないよ。 <EOS>',\n",
       " '<BOS> 大丈夫ですよ。 <EOS>',\n",
       " '<BOS> 了解。 <EOS>',\n",
       " '<BOS> 問題なし。 <EOS>',\n",
       " '<BOS> もう一回。 <EOS>',\n",
       " '<BOS> 座りなよ。 <EOS>',\n",
       " '<BOS> お静かに。 <EOS>',\n",
       " '<BOS> はい、チーズ。 <EOS>',\n",
       " '<BOS> 「お願い」って言えよ。 <EOS>',\n",
       " '<BOS> やって欲しいなら、頼めよ。 <EOS>',\n",
       " '<BOS> 彼女はにっこり笑った。 <EOS>',\n",
       " '<BOS> 彼女は微笑みました。 <EOS>',\n",
       " '<BOS> さあ、みんなで歌いましょう。 <EOS>',\n",
       " '<BOS> 下がってろ！ <EOS>',\n",
       " '<BOS> 眠っちゃダメ。 <EOS>',\n",
       " '<BOS> 黙ってて。 <EOS>',\n",
       " '<BOS> じっとしてて。 <EOS>',\n",
       " '<BOS> そこにいて。 <EOS>',\n",
       " '<BOS> ちょっとどいて。 <EOS>',\n",
       " '<BOS> しっかり勉強して下さい。 <EOS>',\n",
       " '<BOS> バスに乗りなさい。 <EOS>',\n",
       " '<BOS> 話してよ！ <EOS>',\n",
       " '<BOS> 話せよ！ <EOS>',\n",
       " '<BOS> 痛いです。 <EOS>',\n",
       " '<BOS> 痛い。 <EOS>',\n",
       " '<BOS> それは新しいです。 <EOS>',\n",
       " '<BOS> 彼らは挑戦した。 <EOS>',\n",
       " '<BOS> さあ、着きましたよ。 <EOS>',\n",
       " '<BOS> これで最後だ。 <EOS>',\n",
       " '<BOS> 以上です。 <EOS>',\n",
       " '<BOS> これで決まりだ。 <EOS>',\n",
       " '<BOS> これだよ。 <EOS>',\n",
       " '<BOS> これなんです。 <EOS>',\n",
       " '<BOS> これは効くわ。 <EOS>',\n",
       " '<BOS> これでもいいや。 <EOS>',\n",
       " '<BOS> 時のたつのは早いものだ。 <EOS>',\n",
       " '<BOS> 時間終了。 <EOS>',\n",
       " '<BOS> はい、そこまで。 <EOS>',\n",
       " '<BOS> トムは賛成した。 <EOS>',\n",
       " '<BOS> トムは賛成する。 <EOS>',\n",
       " '<BOS> トムはそれを食べた。 <EOS>',\n",
       " '<BOS> トムは踊った。 <EOS>',\n",
       " '<BOS> トムはお酒を飲む。 <EOS>',\n",
       " '<BOS> トムは車を運転します。 <EOS>',\n",
       " '<BOS> トムは失敗した。 <EOS>',\n",
       " '<BOS> トムは忘れた。 <EOS>',\n",
       " '<BOS> トムは喧嘩した。 <EOS>',\n",
       " '<BOS> トムは闘った。 <EOS>',\n",
       " '<BOS> トムは手伝った。 <EOS>',\n",
       " '<BOS> トムは狂ってる。 <EOS>',\n",
       " '<BOS> トムは新人だ。 <EOS>',\n",
       " '<BOS> トムがいません。 <EOS>',\n",
       " '<BOS> トムは濡れてる。 <EOS>',\n",
       " '<BOS> トムはジャンプした。 <EOS>',\n",
       " '<BOS> トムは見た。 <EOS>',\n",
       " '<BOS> トムは頷いた。 <EOS>',\n",
       " '<BOS> トムは電話をかけた。 <EOS>',\n",
       " '<BOS> トムはため息をついた。 <EOS>',\n",
       " '<BOS> トムは微笑んだ。 <EOS>',\n",
       " '<BOS> トムはタバコを吸う。 <EOS>',\n",
       " '<BOS> トムは話した。 <EOS>',\n",
       " '<BOS> トムは待っていた。 <EOS>',\n",
       " '<BOS> トムはウィンクした。 <EOS>',\n",
       " '<BOS> トムはあくびした。 <EOS>',\n",
       " ...]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples = len(target_texts)\n",
    "num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This bird cannot fly.'"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_texts[9000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<BOS> この鳥は飛ぶことができない。 <EOS>'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_texts[9000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "\n",
    "# Process english and french sentences\n",
    "for line in range(len(lines)):\n",
    "    \n",
    "    input_line = str(lines[line]).split('\\t')[0]\n",
    "    \n",
    "    # Append '\\t' for start of the sentence and '\\n' to signify end of the sentence\n",
    "    target_line = '\\t' + str(lines[line]).split('\\t')[1] + '\\n'\n",
    "    input_texts.append(input_line)\n",
    "    target_texts.append(target_line)\n",
    "    \n",
    "    for ch in input_line:\n",
    "        if (ch not in input_characters):\n",
    "            input_characters.add(ch)\n",
    "            \n",
    "    for ch in target_line:\n",
    "        if (ch not in target_characters):\n",
    "            target_characters.add(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Maximum Sentense Length\n",
    "english_maxlen = max([ len(text) for text in input_texts ])\n",
    "japanese_maxlen = max([ len(text) for text in target_texts ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_char_size = len(input_characters)\n",
    "\n",
    "japanese_char_size = len(target_characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3. Vectorization & Dictionary Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_char_index = dict([(char, i) for i, char in enumerate(input_characters)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_char_index = dict([(char, i) for i, char in enumerate(target_characters)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_index_char = dict((i, char) for char, i in input_char_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_index_char = dict((i, char) for char, i in target_char_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D tensor (number of samples, MAX_LEN, dictionary size)\n",
    "encoder_input_data = np.zeros((len(input_texts), english_maxlen, english_char_size), dtype=\"float32\")\n",
    "\n",
    "decoder_input_data = np.zeros((len(input_texts), japanese_maxlen, japanese_char_size), dtype=\"float32\")\n",
    "\n",
    "decoder_output_data = np.zeros((len(input_texts), japanese_maxlen, japanese_char_size), dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 22, 72)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 1476)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 1476)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_output_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, text in enumerate(input_texts):\n",
    "    char = char.lower()\n",
    "    for j, char in enumerate(text):\n",
    "        encoder_input_data[i][j][input_char_index[char]] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, text in enumerate(target_texts):\n",
    "    for j, char in enumerate(text):\n",
    "        decoder_input_data[i][j][target_char_index[char]] = 1.\n",
    "        # Decoder output shifts by one step\n",
    "        if j > 0:\n",
    "            decoder_output_data[i, j-1, target_char_index[char]] = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Modeling Seq2Seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process\n",
    "1. Encode the input sequence into state vectors.\n",
    "2. Start with a target sequence of size 1 (just the start-of-sequence character).\n",
    "3. Feed the state vectors and 1-char target sequence to the decoder to produce predictions for the next character.\n",
    "4. Sample the next character using these predictions (we simply use argmax).\n",
    "5. Append the sampled character to the target sequence\n",
    "6. Repeat until we generate the end-of-sequence character or we hit the character limit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Encoder input data: id word sequence (English)\n",
    "- Encoder input layer: None × 2D matrix of word sequence length\n",
    "- Encoder LSTM layer: number of hidden layer units\n",
    "\n",
    "- Decoder input data: id word sequence (Japanese)\n",
    "- Decoder input layer: None × 2D matrix of word sequence length\n",
    "- Decoder LSTM layer: number of hidden layer units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_DIM = 256\n",
    "NUM_ENCODER_TOKENS = english_char_size\n",
    "NUM_DECODER_TOKENS = japanese_char_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(None, NUM_ENCODER_TOKENS))\n",
    "encoder_LSTM = LSTM(units=HIDDEN_DIM, return_state=True) # this is the key\n",
    "encoder_outputs, state_h, state_c = encoder_LSTM(encoder_inputs) # Ignore encoder output, save only memory cell state\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_inputs = Input(shape=(None, NUM_DECODER_TOKENS))\n",
    "decoder_LSTM = LSTM(units=HIDDEN_DIM, return_sequences=True, return_state=True) # this is the key\n",
    "decoder_outputs, _h, _c = decoder_LSTM(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense = Dense(units=NUM_DECODER_TOKENS, activation=\"softmax\")\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, None, 72)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, None, 1476)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, 256), (None, 336896      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   [(None, None, 256),  1774592     input_4[0][0]                    \n",
      "                                                                 lstm_3[0][1]                     \n",
      "                                                                 lstm_3[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, None, 1476)   379332      lstm_4[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 2,490,820\n",
      "Trainable params: 2,490,820\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Layer works as encoder and decoder\n",
    "\n",
    "- Encoder: Processes the input sequence and returns its own internal state, which serves as the `` context '' and `` state '' of the decoder in the next step.\n",
    "- Decoder: If there is a previous character, it is trained to predict the next character in the target sequence.\n",
    "- Thought Vector: Encoder uses the state vector from Encoder as the initial state. This is a method to get information about what Decoder generates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- return_state constructor argument. \n",
    "- Configure the RNN layer to return a list where the first entry is output and the next entry is an internal RNN state. \n",
    "- This is used to recover the encoder state.\n",
    "\n",
    "- An inital_state call argument that specifies the initial state of the RNN. \n",
    "- This is used to pass the encoder state to the decoder as the initial state.\n",
    "\n",
    "- return_sequences constructor argument. \n",
    "- Set the RNN to return its complete output sequence (not just the last output, which is the default behavior). \n",
    "- This is used in the decoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fitting and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/5\n",
      "8000/8000 [==============================] - 222s 28ms/step - loss: 1.3808 - val_loss: 1.5338\n",
      "Epoch 2/5\n",
      "8000/8000 [==============================] - 228s 29ms/step - loss: 1.1300 - val_loss: 1.3283\n",
      "Epoch 3/5\n",
      "8000/8000 [==============================] - 227s 28ms/step - loss: 0.9960 - val_loss: 1.2301\n",
      "Epoch 4/5\n",
      "8000/8000 [==============================] - 241s 30ms/step - loss: 0.9108 - val_loss: 1.1806\n",
      "Epoch 5/5\n",
      "8000/8000 [==============================] - 247s 31ms/step - loss: 0.8512 - val_loss: 1.1231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\keras\\engine\\network.py:877: UserWarning: Layer lstm_4 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_3/while/Exit_2:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_3/while/Exit_3:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    }
   ],
   "source": [
    "model.fit([encoder_input_data, decoder_input_data], decoder_output_data,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=EPOCHS,\n",
    "          validation_split=0.2)\n",
    "\n",
    "model.save(\"seq2seq_translation.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('seq2seq_translation.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The below step is how to tune the parameters (Dont run the below step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = [32, 64]\n",
    "EPOCHS = [5, 10]\n",
    "\n",
    "for i in range(2):\n",
    "    BATCH_SIZE = BATCH_SIZE[i]\n",
    "    for e in range(2):\n",
    "        EPOCHS = EPOCHS[e]\n",
    "        print(\"------------------------------------\")\n",
    "        print(\"BATCH_SIZE: \", BATCH_SIZE)\n",
    "        print(\"EPOCHS: \", EPOCHS)\n",
    "        history = model.fit([encoder_input_data, decoder_input_data], decoder_output_data,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            epochs=EPOCHS,\n",
    "                            validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(HIDDEN_DIM,))\n",
    "decoder_state_input_c = Input(shape=(HIDDEN_DIM,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_outputs, decoder_h,decoder_c = decoder_LSTM(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [decoder_h, decoder_c ]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(inputs = [decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_translater(english_input):\n",
    "    \n",
    "    encoder_states = encoder_model.predict(english_input)\n",
    "\n",
    "    japanese_seq = np.zeros((1, 1, NUM_DECODER_TOKENS))\n",
    "    japanese_seq[0, 0, target_char_index[bos]] = 1.\n",
    "    \n",
    "    stop_condition = False\n",
    "    japanese_output = \"\"\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([japanese_seq] + encoder_states)\n",
    "        # Softmax returns the id of the largest char np.argmax\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        \n",
    "        # Convert to Japanese word\n",
    "        sampled_char = target_index_char[sampled_token_index]\n",
    "        japanese_output += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length or find stop character.\n",
    "        if (sampled_char == eos or len(japanese_output) > japanese_maxlen):\n",
    "            stop_condition = True\n",
    "\n",
    "        japanese_seq = np.zeros((1, 1, NUM_DECODER_TOKENS))\n",
    "        japanese_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        encoder_states = [_h, _c]\n",
    "\n",
    "    return japanese_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_text = \"I am so tired and I feel bored to go back to my home.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_seq = encoder_input_data[1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'<BOS> '",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-221-198aefdef42b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0minference_translater\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp_seq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-199-d5177277c055>\u001b[0m in \u001b[0;36minference_translater\u001b[1;34m(english_input)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mjapanese_seq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNUM_DECODER_TOKENS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mjapanese_seq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_char_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbos\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mstop_condition\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '<BOS> '"
     ]
    }
   ],
   "source": [
    "inference_translater(inp_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'<BOS> '",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-218-6b78deafe7f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mseq_index\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0minp_seq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder_input_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mseq_index\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mseq_index\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mtranslated_sent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minference_translater\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp_seq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'-'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Input sentence:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_texts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mseq_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-199-d5177277c055>\u001b[0m in \u001b[0;36minference_translater\u001b[1;34m(english_input)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mjapanese_seq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNUM_DECODER_TOKENS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mjapanese_seq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_char_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbos\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mstop_condition\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '<BOS> '"
     ]
    }
   ],
   "source": [
    "for seq_index in range(10):\n",
    "    inp_seq = encoder_input_data[seq_index:seq_index+1]\n",
    "    translated_sent = inference_translater(inp_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('Decoded sentence:', translated_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'ndim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-207-aecdfcc616e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdecode_seq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menglish_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-205-307e3975b50d>\u001b[0m in \u001b[0;36mdecode_seq\u001b[1;34m(inp_seq)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m# Initial states value is coming from the encoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mstates_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp_seq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mtarget_seq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfra_chars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1147\u001b[0m                              'argument.')\n\u001b[0;32m   1148\u001b[0m         \u001b[1;31m# Validate user data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1149\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1150\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 751\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    752\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'DataFrame'\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mstandardize_single_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'DataFrame'\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mstandardize_single_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_single_array\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     25\u001b[0m                 'Got tensor with shape: %s' % str(shape))\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[1;32melif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'ndim'"
     ]
    }
   ],
   "source": [
    "decode_seq(english_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'ndim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-201-cd46ffe70546>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0minference_translater\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menglish_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-199-d5177277c055>\u001b[0m in \u001b[0;36minference_translater\u001b[1;34m(english_input)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0minference_translater\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menglish_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mencoder_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menglish_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mjapanese_seq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNUM_DECODER_TOKENS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1147\u001b[0m                              'argument.')\n\u001b[0;32m   1148\u001b[0m         \u001b[1;31m# Validate user data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1149\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1150\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 751\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    752\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'DataFrame'\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mstandardize_single_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'DataFrame'\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mstandardize_single_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_single_array\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     25\u001b[0m                 'Got tensor with shape: %s' % str(shape))\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[1;32melif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'ndim'"
     ]
    }
   ],
   "source": [
    "inference_translater(english_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
